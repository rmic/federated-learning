[{"year": "2020", "url": "http://arxiv.org/abs/2010.04851", "title": "{Voting-based Approaches For Differentially Private Federated Learning}", "pages": "1--16", "mendeley-tags": "privacy", "keywords": "privacy", "file": ":Users/rm/CETIC/RESEARCH{\\_}THEMES/Federated Learning/2010.04851.pdf:pdf", "eprint": "2010.04851", "author": "Zhu, Yuqing and Yu, Xiang and Tsai, Yi-Hsuan and Pittaluga, Francesco and Faraki, Masoud and Chandraker, Manmohan and Wang, Yu-Xiang", "arxivid": "2010.04851", "archiveprefix": "arXiv", "abstract": "While federated learning (FL) enables distributed agents to collaboratively train a centralized model without sharing data with each other, it fails to protect users against inference attacks that mine private information from the centralized model. Thus, facilitating federated learning methods with differential privacy (DPFL) becomes attractive. Existing algorithms based on privately aggregating clipped gradients require many rounds of communication, which may not converge, and cannot scale up to large-capacity models due to explicit dimension-dependence in its added noise. In this paper, we adopt the knowledge transfer model of private learning pioneered by Papernot et al. (2017; 2018) and extend their algorithm PATE, as well as the recent alternative PrivateKNN (Zhu et al., 2020) to the federated learning setting. The key difference is that our method privately aggregates the labels from the agents in a voting scheme, instead of aggregating the gradients, hence avoiding the dimension dependence and achieving significant savings in communication cost. Theoretically, we show that when the margins of the voting scores are large, the agents enjoy exponentially higher accuracy and stronger (data-dependent) differential privacy guarantees on both agent-level and instance-level. Extensive experiments show that our approach significantly improves the privacy-utility trade-off over the current state-of-the-art in DPFL.", "ENTRYTYPE": "article", "ID": "Zhu2020"}, {"year": "2020", "url": "http://arxiv.org/abs/2009.03561", "title": "{Toward Robustness and Privacy in Federated Learning: Experimenting with Local and Central Differential Privacy}", "mendeley-tags": "privacy", "keywords": "privacy", "file": ":Users/rm/CETIC/RESEARCH{\\_}THEMES/Federated Learning/2009.03561.pdf:pdf", "eprint": "2009.03561", "author": "Naseri, Mohammad and Hayes, Jamie and {De Cristofaro}, Emiliano", "arxivid": "2009.03561", "archiveprefix": "arXiv", "abstract": "Federated Learning (FL) allows multiple participants to collaboratively train machine learning models by keeping their datasets local and exchanging model updates. Recent work has highlighted weaknesses related to robustness and privacy in FL, including backdoor, membership and property inference attacks. In this paper, we investigate whether and how Differential Privacy (DP) can be used to defend against attacks targeting both robustness and privacy in FL. To this end, we present a first-of-its-kind experimental evaluation of Local and Central Differential Privacy (LDP/CDP), assessing their feasibility and effectiveness. We show that both LDP and CDP do defend against backdoor attacks, with varying levels of protection and utility, and overall more effectively than non-DP defenses. They also mitigate white-box membership inference attacks, which our work is the first to show. Neither, however, defend against property inference attacks, prompting the need for further research in this space. Overall, our work also provides a re-usable measurement framework to quantify the trade-offs between robustness/privacy and utility in differentially private FL.", "ENTRYTYPE": "article", "ID": "Naseri2020"}, {"year": "2020", "url": "http://arxiv.org/abs/2010.12229", "title": "{Throughput-Optimal Topology Design for Cross-Silo Federated Learning}", "file": ":Users/rm/CETIC/RESEARCH{\\_}THEMES/Federated Learning/2010.12229.pdf:pdf", "eprint": "2010.12229", "author": "Marfoq, Othmane and Xu, Chuan and Neglia, Giovanni and Vidal, Richard", "arxivid": "2010.12229", "archiveprefix": "arXiv", "abstract": "Federated learning usually employs a client-server architecture where an orchestrator iteratively aggregates model updates from remote clients and pushes them back a refined model. This approach may be inefficient in cross-silo settings, as close-by data silos with high-speed access links may exchange information faster than with the orchestrator, and the orchestrator may become a communication bottleneck. In this paper we define the problem of topology design for cross-silo federated learning using the theory of max-plus linear systems to compute the system throughput---number of communication rounds per time unit. We also propose practical algorithms that, under the knowledge of measurable network characteristics, find a topology with the largest throughput or with provable throughput guarantees. In realistic Internet networks with 10 Gbps access links for silos, our algorithms speed up training by a factor 9 and 1.5 in comparison to the master-slave architecture and to state-of-the-art MATCHA, respectively. Speedups are even larger with slower access links.", "ENTRYTYPE": "article", "ID": "Marfoq2020"}, {"year": "2020", "volume": "3", "title": "{The future of digital health with federated learning}", "number": "1", "mendeley-tags": "usecases", "keywords": "usecases", "journal": "npj Digital Medicine", "issn": "23986352", "file": ":Users/rm/CETIC/RESEARCH{\\_}THEMES/Federated Learning/2003.08119v1.pdf:pdf", "eprint": "2003.08119", "doi": "10.1038/s41746-020-00323-1", "author": "Rieke, Nicola and Hancox, Jonny and Li, Wenqi and Milletar{\u00ec}, Fausto and Roth, Holger R. and Albarqouni, Shadi and Bakas, Spyridon and Galtier, Mathieu N. and Landman, Bennett A. and Maier-Hein, Klaus and Ourselin, S{\u00e9}bastien and Sheller, Micah and Summers, Ronald M. and Trask, Andrew and Xu, Daguang and Baust, Maximilian and Cardoso, M. Jorge", "arxivid": "2003.08119", "archiveprefix": "arXiv", "abstract": "Data-driven machine learning (ML) has emerged as a promising approach for building accurate and robust statistical models from medical data, which is collected in huge volumes by modern healthcare systems. Existing medical data is not fully exploited by ML primarily because it sits in data silos and privacy concerns restrict access to this data. However, without access to sufficient data, ML will be prevented from reaching its full potential and, ultimately, from making the transition from research to clinical practice. This paper considers key factors contributing to this issue, explores how federated learning (FL) may provide a solution for the future of digital health and highlights the challenges and considerations that need to be addressed.", "ENTRYTYPE": "article", "ID": "Rieke2020"}, {"year": "2020", "url": "http://arxiv.org/abs/2010.06053", "title": "{TextHide: Tackling Data Privacy in Language Understanding Tasks}", "mendeley-tags": "security", "keywords": "security", "file": ":Users/rm/CETIC/RESEARCH{\\_}THEMES/Federated Learning/2010.06053.pdf:pdf", "eprint": "2010.06053", "author": "Huang, Yangsibo and Song, Zhao and Chen, Danqi and Li, Kai and Arora, Sanjeev", "arxivid": "2010.06053", "archiveprefix": "arXiv", "abstract": "An unsolved challenge in distributed or federated learning is to effectively mitigate privacy risks without slowing down training or reducing accuracy. In this paper, we propose TextHide aiming at addressing this challenge for natural language understanding tasks. It requires all participants to add a simple encryption step to prevent an eavesdropping attacker from recovering private text data. Such an encryption step is efficient and only affects the task performance slightly. In addition, TextHide fits well with the popular framework of fine-tuning pre-trained language models (e.g., BERT) for any sentence or sentence-pair task. We evaluate TextHide on the GLUE benchmark, and our experiments show that TextHide can effectively defend attacks on shared gradients or representations and the averaged accuracy reduction is only {\\$}1.9\\backslash{\\%}{\\$}. We also present an analysis of the security of TextHide using a conjecture about the computational intractability of a mathematical problem. Our code is available at https://github.com/Hazelsuko07/TextHide", "ENTRYTYPE": "article", "ID": "Huang2020"}, {"year": "2020", "url": "http://arxiv.org/abs/2010.08730", "title": "{Secure Weighted Aggregation in Federated Learning}", "mendeley-tags": "security", "keywords": "data disparity evaluation,federated learning,homomorphic encryption,secure aggregation,security,zero-knowledge proof", "isbn": "9781450381048", "file": ":Users/rm/CETIC/RESEARCH{\\_}THEMES/Federated Learning/2010.08730.pdf:pdf", "eprint": "2010.08730", "author": "Guo, Jiale and Liu, Ziyao and Lam, Kwok-Yan and Zhao, Jun and Chen, Yiqiang and Xing, Chaoping", "arxivid": "2010.08730", "archiveprefix": "arXiv", "abstract": "Federated learning (FL) schemes enable multiple clients to jointly solve a machine learning problem using their local data to train a local model, then aggregating these models under the coordination of a central server. To achieve such a practical FL system, we need to consider (i) how to deal with the disparity across clients' datasets, and (ii) how to further protect the privacy of clients' locally trained models, which may leak information. The first concern can be addressed using a weighted aggregation scheme where the weights of clients are determined based on their data size and quality. Approaches in previous works result in a good performance but do not provide any privacy guarantee. For the second concern, privacy-preserving aggregation schemes can provide privacy guarantees that can be mathematically analyzed. However, the security issue still exists that both the central server and clients may send fraudulent messages to each other for their own benefits, especially if there is an incentive mechanism where the reward provided by the server is distributed according to clients' weights. To address the issues mentioned above, we propose a secure weighted aggregation scheme. Precisely, relying on the homomorphic encryption (HE) crypto-system, each client's weight is calculated in a privacy-preserving manner. Furthermore, we adopt a zero-knowledge proof (ZKP) based verification scheme to prevent the central server and clients from receiving fraudulent messages from each other. To the best of our knowledge, this work proposes the first aggregation scheme to deal with data disparity and fraudulent messages in the FL system from both privacy and security perspective.", "ENTRYTYPE": "article", "ID": "Guo2020"}, {"year": "2020", "url": "http://arxiv.org/abs/2009.14388", "title": "{Secure Aggregation with Heterogeneous Quantization in Federated Learning}", "pages": "1--34", "mendeley-tags": "security", "keywords": "security", "file": ":Users/rm/CETIC/RESEARCH{\\_}THEMES/Federated Learning/2009.14388.pdf:pdf", "eprint": "2009.14388", "author": "Elkordy, Ahmed Roushdy and Avestimehr, A. Salman", "arxivid": "2009.14388", "archiveprefix": "arXiv", "abstract": "Secure model aggregation across many users is a key component of federated learning systems. The state-of-the-art protocols for secure model aggregation, which are based on additive masking, require all users to quantize their model updates to the same level of quantization. This severely degrades their performance due to lack of adaptation to available bandwidth at different users. We propose three schemes that allow secure model aggregation while using heterogeneous quantization. This enables the users to adjust their quantization proportional to their available bandwidth, which can provide a substantially better trade-off between the accuracy of training and the communication time. The proposed schemes are based on a grouping strategy by partitioning the network into groups, and partitioning the local model updates of users into segments. Instead of applying aggregation protocol to the entire local model update vector, it is applied on segments with specific coordination between users. We theoretically evaluate the quantization error for our schemes, and also demonstrate how our schemes can be utilized to overcome Byzantine users.", "ENTRYTYPE": "article", "ID": "Elkordy2020"}, {"year": "2020", "title": "{Robust and Communication-Efficient Federated Learning from Non-i.i.d. Data}", "pmid": "31689214", "mendeley-tags": "concepts", "keywords": "Deep learning,concepts,distributed learning,efficient communication,federated learning,privacy-preserving machine learning", "journal": "IEEE Transactions on Neural Networks and Learning Systems", "issn": "21622388", "eprint": "1903.02891", "doi": "10.1109/TNNLS.2019.2944481", "author": "Sattler, Felix and Wiedemann, Simon and Muller, Klaus Robert and Samek, Wojciech", "arxivid": "1903.02891", "archiveprefix": "arXiv", "abstract": "Federated learning allows multiple parties to jointly train a deep learning model on their combined data, without any of the participants having to reveal their local data to a centralized server. This form of privacy-preserving collaborative learning, however, comes at the cost of a significant communication overhead during training. To address this problem, several compression methods have been proposed in the distributed training literature that can reduce the amount of required communication by up to three orders of magnitude. These existing methods, however, are only of limited utility in the federated learning setting, as they either only compress the upstream communication from the clients to the server (leaving the downstream communication uncompressed) or only perform well under idealized conditions, such as i.i.d. distribution of the client data, which typically cannot be found in federated learning. In this article, we propose sparse ternary compression (STC), a new compression framework that is specifically designed to meet the requirements of the federated learning environment. STC extends the existing compression technique of top- k gradient sparsification with a novel mechanism to enable downstream compression as well as ternarization and optimal Golomb encoding of the weight updates. Our experiments on four different learning tasks demonstrate that STC distinctively outperforms federated averaging in common federated learning scenarios. These results advocate for a paradigm shift in federated optimization toward high-frequency low-bitwidth communication, in particular in the bandwidth-constrained learning environments.", "ENTRYTYPE": "article", "ID": "Sattler2020"}, {"year": "2020", "url": "http://arxiv.org/abs/2009.08294", "title": "{Robust Aggregation for Adaptive Privacy Preserving Federated Learning in Healthcare}", "mendeley-tags": "security", "keywords": "allows dl models to,and laws,byzan-,federated learning,fl,healthcare,poisoning attacks,privacy preserving machine learning,security,tine robust aggregation,train collab-", "file": ":Users/rm/CETIC/RESEARCH{\\_}THEMES/Federated Learning/2009.08294.pdf:pdf", "eprint": "2009.08294", "author": "Grama, Matei and Musat, Maria and Mu{\u00f1}oz-Gonz{\u00e1}lez, Luis and Passerat-Palmbach, Jonathan and Rueckert, Daniel and Alansary, Amir", "arxivid": "2009.08294", "archiveprefix": "arXiv", "abstract": "Federated learning (FL) has enabled training models collaboratively from multiple data owning parties without sharing their data. Given the privacy regulations of patient's healthcare data, learning-based systems in healthcare can greatly benefit from privacy-preserving FL approaches. However, typical model aggregation methods in FL are sensitive to local model updates, which may lead to failure in learning a robust and accurate global model. In this work, we implement and evaluate different robust aggregation methods in FL applied to healthcare data. Furthermore, we show that such methods can detect and discard faulty or malicious local clients during training. We run two sets of experiments using two real-world healthcare datasets for training medical diagnosis classification tasks. Each dataset is used to simulate the performance of three different robust FL aggregation strategies when facing different poisoning attacks. The results show that privacy preserving methods can be successfully applied alongside Byzantine-robust aggregation techniques. We observed in particular how using differential privacy (DP) did not significantly impact the final learning convergence of the different aggregation strategies.", "ENTRYTYPE": "article", "ID": "Grama2020"}, {"year": "2020", "url": "http://arxiv.org/abs/2010.07733", "title": "{R-GAP: Recursive Gradient Attack on Privacy}", "number": "ii", "mendeley-tags": "security", "keywords": "security", "file": ":Users/rm/CETIC/RESEARCH{\\_}THEMES/Federated Learning/2010.07733.pdf:pdf", "eprint": "2010.07733", "author": "Zhu, Junyi and Blaschko, Matthew", "arxivid": "2010.07733", "archiveprefix": "arXiv", "abstract": "Federated learning frameworks have been regarded as a promising approach to break the dilemma between demands on privacy and the promise of learning from large collections of distributed data. Many such frameworks only ask collaborators to share their local update of a common model, i.e. gradients with respect to locally stored data, instead of exposing their raw data to other collaborators. However, recent optimization-based gradient attacks show that raw data can often be accurately recovered from gradients. It has been shown that minimizing the Euclidean distance between true gradients and those calculated from estimated data is often effective in fully recovering private data. However, there is a fundamental lack of theoretical understanding of how and when gradients can lead to unique recovery of original data. Our research fills this gap by providing a closed-form recursive procedure to recover data from gradients in deep neural networks. We demonstrate that gradient attacks consist of recursively solving a sequence of systems of linear equations. Furthermore, our closed-form approach works as well as or even better than optimization-based approaches at a fraction of the computation, we name it Recursive Gradient Attack on Privacy (R-GAP). Additionally, we propose a rank analysis method, which can be used to estimate a network architecture's risk of a gradient attack. Experimental results demonstrate the validity of the closed-form attack and rank analysis, while demonstrating its superior computational properties and lack of susceptibility to local optima vis a vis optimization-based attacks. Source code is available for download from https://github.com/JunyiZhu-AI/R-GAP.", "ENTRYTYPE": "article", "ID": "Zhu2020a"}, {"year": "2019", "volume": "11861 LNCS", "title": "{Privacy-Preserving Federated Brain Tumour Segmentation}", "pages": "133--141", "mendeley-tags": "usecases", "keywords": "usecases", "journal": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)", "issn": "16113349", "isbn": "9783030326913", "file": ":Users/rm/CETIC/RESEARCH{\\_}THEMES/Federated Learning/1910.00962.pdf:pdf", "eprint": "1910.00962", "doi": "10.1007/978-3-030-32692-0_16", "author": "Li, Wenqi and Milletar{\u00ec}, Fausto and Xu, Daguang and Rieke, Nicola and Hancox, Jonny and Zhu, Wentao and Baust, Maximilian and Cheng, Yan and Ourselin, S{\u00e9}bastien and Cardoso, M. Jorge and Feng, Andrew", "arxivid": "1910.00962", "archiveprefix": "arXiv", "abstract": "Due to medical data privacy regulations, it is often infeasible to collect and share patient data in a centralised data lake. This poses challenges for training machine learning algorithms, such as deep convolutional networks, which often require large numbers of diverse training examples. Federated learning sidesteps this difficulty by bringing code to the patient data owners and only sharing intermediate model training updates among them. Although a high-accuracy model could be achieved by appropriately aggregating these model updates, the model shared could indirectly leak the local training examples. In this paper, we investigate the feasibility of applying differential-privacy techniques to protect the patient data in a federated learning setup. We implement and evaluate practical federated learning systems for brain tumour segmentation on the BraTS dataset. The experimental results show that there is a trade-off between model performance and privacy protection costs.", "ENTRYTYPE": "article", "ID": "Li2019"}, {"year": "2017", "title": "{Practical secure aggregation for privacy-preserving machine learning}", "pages": "1175--1191", "mendeley-tags": "security", "keywords": "Federated Learning,Machine Learning,Privacy-Preserving Protocols,Secure Aggregation,security", "journal": "Proceedings of the ACM Conference on Computer and Communications Security", "issn": "15437221", "isbn": "9781450349468", "file": ":Users/rm/CETIC/RESEARCH{\\_}THEMES/Federated Learning/2017-281.pdf:pdf", "doi": "10.1145/3133956.3133982", "author": "Bonawitz, Keith and Ivanov, Vladimir and Kreuter, Ben and Marcedone, Antonio and McMahan, H. Brendan and Patel, Sarvar and Ramage, Daniel and Segal, Aaron and Seth, Karn", "abstract": "We design a novel, communication-efficient, failure-robust protocol for secure aggregation of high-dimensional data. Our protocol allows a server to compute the sum of large, user-held data vectors from mobile devices in a secure manner (i.e. without learning each user's individual contribution), and can be used, for example, in a federated learning setting, to aggregate user-provided model updates for a deep neural network. We prove the security of our protocol in the honest-but-curious and active adversary settings, and show that security is maintained even if an arbitrarily chosen subset of users drop out at any time. We evaluate the efficiency of our protocol and show, by complexity analysis and a concrete implementation, that its runtime and communication overhead remain low even on large data sets and client pools. For 16-bit input values, our protocol offers 1.73\u00d7 communication expansion for 210 users and 220-dimensional vectors, and 1.98\u00d7 expansion for 214 users and 224-dimensional vectors over sending data in the clear.", "ENTRYTYPE": "article", "ID": "Bonawitz2017"}, {"year": "2020", "title": "{Performance Optimization of Federated Person Re-identification via Benchmark Analysis}", "pages": "955--963", "keywords": "acm reference format,daiying yin,federated learning,person re-identification,weiming zhuang,xin gan,xuesen zhang,yonggang wen", "isbn": "9781450379885", "file": ":Users/rm/CETIC/RESEARCH{\\_}THEMES/Federated Learning/2008.11560.pdf:pdf", "eprint": "2008.11560", "doi": "10.1145/3394171.3413814", "author": "Zhuang, Weiming and Wen, Yonggang and Zhang, Xuesen and Gan, Xin and Yin, Daiying and Zhou, Dongzhan and Zhang, Shuai and Yi, Shuai", "arxivid": "2008.11560", "archiveprefix": "arXiv", "abstract": "Federated learning is a privacy-preserving machine learning technique that learns a shared model across decentralized clients. It can alleviate privacy concerns of personal re-identification, an important computer vision task. In this work, we implement federated learning to person re-identification (FedReID) and optimize its performance affected by statistical heterogeneity in the real-world scenario. We first construct a new benchmark to investigate the performance of FedReID. This benchmark consists of (1) nine datasets with different volumes sourced from different domains to simulate the heterogeneous situation in reality, (2) two federated scenarios, and (3) an enhanced federated algorithm for FedReID. The benchmark analysis shows that the client-edge-cloud architecture, represented by the federated-by-dataset scenario, has better performance than client-server architecture in FedReID. It also reveals the bottlenecks of FedReID under the real-world scenario, including poor performance of large datasets caused by unbalanced weights in model aggregation and challenges in convergence. Then we propose two optimization methods: (1) To address the unbalanced weight problem, we propose a new method to dynamically change the weights according to the scale of model changes in clients in each training round; (2) To facilitate convergence, we adopt knowledge distillation to refine the server model with knowledge generated from client models on a public dataset. Experiment results demonstrate that our strategies can achieve much better convergence with superior performance on all datasets. We believe that our work will inspire the community to further explore the implementation of federated learning on more computer vision tasks in real-world scenarios.", "ENTRYTYPE": "article", "ID": "Zhuang2020"}, {"year": "2020", "url": "http://arxiv.org/abs/2010.13600", "title": "{Optimal Importance Sampling for Federated Learning}", "pages": "1--5", "number": "3", "file": ":Users/rm/CETIC/RESEARCH{\\_}THEMES/Federated Learning/2010.13600.pdf:pdf", "eprint": "2010.13600", "author": "Rizk, Elsa and Vlaski, Stefan and Sayed, Ali H.", "arxivid": "2010.13600", "archiveprefix": "arXiv", "abstract": "Federated learning involves a mixture of centralized and decentralized processing tasks, where a server regularly selects a sample of the agents and these in turn sample their local data to compute stochastic gradients for their learning updates. This process runs continually. The sampling of both agents and data is generally uniform; however, in this work we consider non-uniform sampling. We derive optimal importance sampling strategies for both agent and data selection and show that non-uniform sampling without replacement improves the performance of the original FedAvg algorithm. We run experiments on a regression and classification problem to illustrate the theoretical results.", "ENTRYTYPE": "article", "ID": "Rizk2020"}, {"year": "2020", "title": "{Optimal Gradient Compression for Distributed and Federated Learning}", "pages": "1--27", "file": ":Users/rm/CETIC/RESEARCH{\\_}THEMES/Federated Learning/2010.03246.pdf:pdf", "eprint": "arXiv:2010.03246v1", "author": "Albasyoni, Alyazeed and Condat, Laurent and Richt, Peter", "arxivid": "arXiv:2010.03246v1", "archiveprefix": "arXiv", "ENTRYTYPE": "article", "ID": "Albasyoni2020"}, {"year": "2020", "url": "http://arxiv.org/abs/2011.01813", "title": "{One-Shot Federated Learning with Neuromorphic Processors}", "pages": "1--5", "keywords": "data privacy,federated learning,neuromorphic computing,one-shot learning", "file": ":Users/rm/CETIC/RESEARCH{\\_}THEMES/Federated Learning/2011.01813.pdf:pdf", "eprint": "2011.01813", "author": "Stewart, Kenneth and Gu, Yanqi", "arxivid": "2011.01813", "archiveprefix": "arXiv", "abstract": "Being very low power, the use of neuromorphic processors in mobile devices to solve machine learning problems is a promising alternative to traditional Von Neumann processors. Federated Learning enables entities such as mobile devices to collaboratively learn a shared model while keeping their training data local. Additionally, federated learning is a secure way of learning because only the model weights need to be shared between models, keeping the data private. Here we demonstrate the efficacy of federated learning in neuromorphic processors. Neuromorphic processors benefit from the collaborative learning, achieving state of the art accuracy on a one-shot learning gesture recognition task across individual processor models while preserving local data privacy.", "ENTRYTYPE": "article", "ID": "Stewart2020"}, {"year": "2019", "volume": "11383 LNCS", "title": "{Multi-institutional deep learning modeling without sharing patient data: A feasibility study on brain tumor segmentation}", "pages": "92--104", "mendeley-tags": "usecases", "keywords": "BraTS,Deep learning,Federated,Glioma,Incremental,Machine learning,Segmentation,usecases", "journal": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)", "issn": "16113349", "isbn": "9783030117221", "file": ":Users/rm/CETIC/RESEARCH{\\_}THEMES/Federated Learning/1810.04304.pdf:pdf", "eprint": "arXiv:1810.04304v2", "doi": "10.1007/978-3-030-11723-8_9", "author": "Sheller, Micah J. and Reina, G. Anthony and Edwards, Brandon and Martin, Jason and Bakas, Spyridon", "arxivid": "arXiv:1810.04304v2", "archiveprefix": "arXiv", "abstract": "Deep learning models for semantic segmentation of images require large amounts of data. In the medical imaging domain, acquiring sufficient data is a significant challenge. Labeling medical image data requires expert knowledge. Collaboration between institutions could address this challenge, but sharing medical data to a centralized location faces various legal, privacy, technical, and data-ownership challenges, especially among international institutions. In this study, we introduce the first use of federated learning for multi-institutional collaboration, enabling deep learning modeling without sharing patient data. Our quantitative results demonstrate that the performance of federated semantic segmentation models (Dice = 0.852) on multimodal brain scans is similar to that of models trained by sharing data (Dice = 0.862). We compare federated learning with two alternative collaborative learning methods and find that they fail to match the performance of federated learning.", "ENTRYTYPE": "article", "ID": "Sheller2019"}, {"year": "2020", "url": "http://arxiv.org/abs/2010.00753", "title": "{Model-sharing Games: Analyzing Federated Learning Under Voluntary Participation}", "file": ":Users/rm/CETIC/RESEARCH{\\_}THEMES/Federated Learning/2010.00753.pdf:pdf", "eprint": "2010.00753", "author": "Donahue, Kate and Kleinberg, Jon", "arxivid": "2010.00753", "archiveprefix": "arXiv", "abstract": "Federated learning is a setting where agents, each with access to their own data source, combine models learned from local data to create a global model. If agents are drawing their data from different distributions, though, federated learning might produce a biased global model that is not optimal for each agent. This means that agents face a fundamental question: should they join the global model or stay with their local model? In this work, we show how this situation can be naturally analyzed through the framework of coalitional game theory. Motivated by these considerations, we propose the following game: there are heterogeneous players with different model parameters governing their data distribution and different amounts of data they have noisily drawn from their own distribution. Each player's goal is to obtain a model with minimal expected mean squared error (MSE) on their own distribution. They have a choice of fitting a model based solely on their own data, or combining their learned parameters with those of some subset of the other players. Combining models reduces the variance component of their error through access to more data, but increases the bias because of the heterogeneity of distributions. In this work, we derive exact expected MSE values for problems in linear regression and mean estimation. We use these values to analyze the resulting game in the framework of hedonic game theory; we study how players might divide into coalitions, where each set of players within a coalition jointly constructs a single model. In a case with arbitrarily many players that each have either a \"small\" or \"large\" amount of data, we constructively show that there always exists a stable partition of players into coalitions.", "ENTRYTYPE": "article", "ID": "Donahue2020"}, {"year": "2020", "url": "http://arxiv.org/abs/2010.10572", "title": "{Mitigating Sybil Attacks on Differential Privacy based Federated Learning}", "pages": "1--8", "mendeley-tags": "security", "keywords": "security", "file": ":Users/rm/CETIC/RESEARCH{\\_}THEMES/Federated Learning/2010.10572.pdf:pdf", "eprint": "2010.10572", "author": "Jiang, Yupeng and Li, Yong and Zhou, Yipeng and Zheng, Xi", "arxivid": "2010.10572", "archiveprefix": "arXiv", "abstract": "In federated learning, machine learning and deep learning models are trained globally on distributed devices. The state-of-the-art privacy-preserving technique in the context of federated learning is user-level differential privacy. However, such a mechanism is vulnerable to some specific model poisoning attacks such as Sybil attacks. A malicious adversary could create multiple fake clients or collude compromised devices in Sybil attacks to mount direct model updates manipulation. Recent works on novel defense against model poisoning attacks are difficult to detect Sybil attacks when differential privacy is utilized, as it masks clients' model updates with perturbation. In this work, we implement the first Sybil attacks on differential privacy based federated learning architectures and show their impacts on model convergence. We randomly compromise some clients by manipulating different noise levels reflected by the local privacy budget epsilon of differential privacy on the local model updates of these Sybil clients such that the global model convergence rates decrease or even leads to divergence. We apply our attacks to two recent aggregation defense mechanisms, called Krum and Trimmed Mean. Our evaluation results on the MNIST and CIFAR-10 datasets show that our attacks effectively slow down the convergence of the global models. We then propose a method to keep monitoring the average loss of all participants in each round for convergence anomaly detection and defend our Sybil attacks based on the prediction cost reported from each client. Our empirical study demonstrates that our defense approach effectively mitigates the impact of our Sybil attacks on model convergence.", "ENTRYTYPE": "article", "ID": "Jiang2020"}, {"year": "2020", "url": "http://arxiv.org/abs/2010.07541", "title": "{Mitigating Byzantine Attacks in Federated Learning}", "pages": "1--9", "mendeley-tags": "security", "keywords": "security", "file": ":Users/rm/CETIC/RESEARCH{\\_}THEMES/Federated Learning/2010.07541.pdf:pdf", "eprint": "2010.07541", "author": "Prakash, Saurav and Avestimehr, Amir Salman", "arxivid": "2010.07541", "archiveprefix": "arXiv", "abstract": "Prior solutions for mitigating Byzantine failures in federated learning, such as element-wise median of the stochastic gradient descent (SGD) based updates from the clients, tend to leverage the similarity of updates from the non-Byzantine clients. However, when data is non-IID, as is typical in mobile networks, the updates received from non-Byzantine clients are quite diverse, resulting in poor convergence performance of such approaches. On the other hand, current algorithms that address heterogeneous data distribution across clients are limited in scope and do not perform well when there is variability in the number and identities of the Byzantine clients, or when general non-convex loss functions are considered. We propose `DiverseFL' that jointly addresses three key challenges of Byzantine resilient federated learning -- (i) non-IID data distribution across clients, (ii) variable Byzantine fault model, and (iii) generalization to non-convex and non-smooth optimization. DiverseFL leverages computing capability of the federated learning server that for each iteration, computes a `guiding' gradient for each client over a tiny sample of data received only once from the client before start of the training. The server uses `per client' criteria for flagging Byzantine clients, by comparing the corresponding guiding gradient with the client's gradient update. The server then updates the model using the gradients received from the non-flagged clients. As we demonstrate in our experiments with benchmark datasets and popular Byzantine attacks, our proposed approach performs better than the prior algorithms, almost matching the performance of the `Oracle SGD', where the server knows the identities of the Byzantine clients.", "ENTRYTYPE": "article", "ID": "Prakash2020"}, {"year": "2020", "url": "http://arxiv.org/abs/2009.12999", "title": "{Loosely Coupled Federated Learning Over Generative Models}", "file": ":Users/rm/CETIC/RESEARCH{\\_}THEMES/Federated Learning/2009.12999.pdf:pdf", "eprint": "2009.12999", "author": "Song, Shaoming and Shao, Yunfeng and Li, Jian", "arxivid": "2009.12999", "archiveprefix": "arXiv", "abstract": "Federated learning (FL) was proposed to achieve collaborative machine learning among various clients without uploading private data. However, due to model aggregation strategies, existing frameworks require strict model homogeneity, limiting the application in more complicated scenarios. Besides, the communication cost of FL's model and gradient transmission is extremely high. This paper proposes Loosely Coupled Federated Learning (LC-FL), a framework using generative models as transmission media to achieve low communication cost and heterogeneous federated learning. LC-FL can be applied on scenarios where clients possess different kinds of machine learning models. Experiments on real-world datasets covering different multiparty scenarios demonstrate the effectiveness of our proposal.", "ENTRYTYPE": "article", "ID": "Song2020"}, {"year": "2020", "volume": "1", "url": "http://arxiv.org/abs/2011.02828", "title": "{Local SGD: Unified Theory and New Efficient Methods}", "number": "3", "file": ":Users/rm/CETIC/RESEARCH{\\_}THEMES/Federated Learning/2011.02828.pdf:pdf", "eprint": "2011.02828", "author": "Gorbunov, Eduard and Hanzely, Filip and Richt{\u00e1}rik, Peter", "arxivid": "2011.02828", "archiveprefix": "arXiv", "abstract": "We present a unified framework for analyzing local SGD methods in the convex and strongly convex regimes for distributed/federated training of supervised machine learning models. We recover several known methods as a special case of our general framework, including Local-SGD/FedAvg, SCAFFOLD, and several variants of SGD not originally designed for federated learning. Our framework covers both the identical and heterogeneous data settings, supports both random and deterministic number of local steps, and can work with a wide array of local stochastic gradient estimators, including shifted estimators which are able to adjust the fixed points of local iterations for faster convergence. As an application of our framework, we develop multiple novel FL optimizers which are superior to existing methods. In particular, we develop the first linearly converging local SGD method which does not require any data homogeneity or other strong assumptions.", "ENTRYTYPE": "article", "ID": "Gorbunov2020"}, {"year": "2020", "url": "http://arxiv.org/abs/2010.12998", "title": "{Local Averaging Helps: Hierarchical Federated Learning and Convergence Analysis}", "pages": "1--29", "mendeley-tags": "concepts", "keywords": "concepts", "file": ":Users/rm/CETIC/RESEARCH{\\_}THEMES/Federated Learning/2010.12998.pdf:pdf", "eprint": "2010.12998", "author": "Wang, Jiayi and Wang, Shiqiang and Chen, Rong-Rong and Ji, Mingyue", "arxivid": "2010.12998", "archiveprefix": "arXiv", "abstract": "Federated learning is an effective approach to realize collaborative learning among edge devices without exchanging raw data. In practice, these devices may connect to local hubs which are then connected to the global server (aggregator). Due to the (possibly limited) computation capability of these local hubs, it is reasonable to assume that they can perform simple averaging operations. A natural question is whether such local averaging is beneficial under different system parameters and how much gain can be obtained compared to the case without such averaging. In this paper, we study hierarchical federated learning with stochastic gradient descent (HF-SGD) and conduct a thorough theoretical analysis to analyze its convergence behavior. The analysis demonstrates the impact of local averaging precisely as a function of system parameters. Due to the higher communication cost of global averaging, a strategy of decreasing the global averaging frequency and increasing the local averaging frequency is proposed. Experiments validate the proposed theoretical analysis and the advantages of hierarchical federated learning.", "ENTRYTYPE": "article", "ID": "Wang2020"}, {"year": "2019", "title": "{Incentive Mechanism for Reliable Federated Learning: A Joint Optimization Approach to Combining Reputation and Contract Theory}", "keywords": "Blockchain,contract theory,federated learning,mobile networks,reputation,security and privacy", "journal": "IEEE Internet of Things Journal", "issn": "23274662", "doi": "10.1109/JIOT.2019.2940820", "author": "Kang, Jiawen and Xiong, Zehui and Niyato, Dusit and Xie, Shengli and Zhang, Junshan", "abstract": "Federated learning is an emerging machine learning technique that enables distributed model training using local datasets from large-scale nodes, e.g., mobile devices, but shares only model updates without uploading the raw training data. This technique provides a promising privacy preservation for mobile devices while simultaneously ensuring high learning performance. The majority of existing work has focused on designing advanced learning algorithms with an aim to achieve better learning performance. However, the challenges, such as incentive mechanisms for participating in training and worker (i.e., mobile devices) selection schemes for reliable federated learning, have not been explored yet. These challenges have hindered the widespread adoption of federated learning. To address the above challenges, in this article, we first introduce reputation as the metric to measure the reliability and trustworthiness of the mobile devices. We then design a reputation-based worker selection scheme for reliable federated learning by using a multiweight subjective logic model. We also leverage the blockchain to achieve secure reputation management for workers with nonrepudiation and tamper-resistance properties in a decentralized manner. Moreover, we propose an effective incentive mechanism combining reputation with contract theory to motivate high-reputation mobile devices with high-quality data to participate in model learning. Numerical results clearly indicate that the proposed schemes are efficient for reliable federated learning in terms of significantly improving the learning accuracy.", "ENTRYTYPE": "article", "ID": "Kang2019"}, {"year": "2019", "title": "{In-edge AI: Intelligentizing mobile edge computing, caching and communication by federated learning}", "journal": "IEEE Network", "issn": "1558156X", "eprint": "1809.07857", "doi": "10.1109/MNET.2019.1800286", "author": "Wang, Xiaofei and Han, Yiwen and Wang, Chenyang and Zhao, Qiyang and Chen, Xu and Chen, Min", "arxivid": "1809.07857", "archiveprefix": "arXiv", "abstract": "Recently, along with the rapid development of mobile communication technology, edge computing theory and techniques have been attracting more and more attention from global researchers and engineers, which can significantly bridge the capacity of cloud and requirement of devices by the network edges, and thus can accelerate content delivery and improve the quality of mobile services. In order to bring more intelligence to edge systems, compared to traditional optimization methodology, and driven by the current deep learning techniques, we propose to integrate the Deep Reinforcement Learning techniques and Federated Learning framework with mobile edge systems, for optimizing mobile edge computing, caching and communication. And thus, we design the \"In-Edge AI\" framework in order to intelligently utilize the collaboration among devices and edge nodes to exchange the learning parameters for a better training and inference of the models, and thus to carry out dynamic system-level optimization and application-level enhancement while reducing the unnecessary system communication load. \"In-Edge AI\" is evaluated and proved to have near-optimal performance but relatively low overhead of learning, while the system is cognitive and adaptive to mobile communication systems. Finally, we discuss several related challenges and opportunities for unveili", "ENTRYTYPE": "article", "ID": "Wang2019"}, {"year": "2020", "url": "http://arxiv.org/abs/2010.15582", "title": "{Improving Accuracy of Federated Learning in Non-IID Settings}", "file": ":Users/rm/CETIC/RESEARCH{\\_}THEMES/Federated Learning/2010.15582.pdf:pdf", "eprint": "2010.15582", "author": "Ozdayi, Mustafa Safa and Kantarcioglu, Murat and Iyer, Rishabh", "arxivid": "2010.15582", "archiveprefix": "arXiv", "abstract": "Federated Learning (FL) is a decentralized machine learning protocol that allows a set of participating agents to collaboratively train a model without sharing their data. This makes FL particularly suitable for settings where data privacy is desired. However, it has been observed that the performance of FL is closely tied with the local data distributions of agents. Particularly, in settings where local data distributions vastly differ among agents, FL performs rather poorly with respect to the centralized training. To address this problem, we hypothesize the reasons behind the performance degradation, and develop some techniques to address these reasons accordingly. In this work, we identify four simple techniques that can improve the performance of trained models without incurring any additional communication overhead to FL, but rather, some light computation overhead either on the client, or the server-side. In our experimental analysis, combination of our techniques improved the validation accuracy of a model trained via FL by more than 12{\\%} with respect to our baseline. This is about 5{\\%} less than the accuracy of the model trained on centralized data.", "ENTRYTYPE": "article", "ID": "Ozdayi2020"}, {"year": "2020", "url": "http://arxiv.org/abs/2010.10996", "title": "{GFL: A Decentralized Federated Learning Framework Based On Blockchain}", "mendeley-tags": "framework", "keywords": "framework", "file": ":Users/rm/CETIC/RESEARCH{\\_}THEMES/Federated Learning/2010.10996.pdf:pdf", "eprint": "2010.10996", "author": "Hu, Yifan and Xia, Wei and Xiao, Jun and Wu, Chao", "arxivid": "2010.10996", "archiveprefix": "arXiv", "abstract": "With the increasing importance of data privacy protection, federated learning is becoming more widely used, and there are more frameworks for federated learning. However, the centralization of federated learning has always restricted the development of federated learning and the federated learning framework. Although there are some decentralized federated learning algorithms, these algorithms have some shortcomings and there is no framework that can quickly use these algorithms. In this paper,we proposed and implemented a blockchain-based decentralized federated learning framework called GFL $\\backslash$cite{\\{}GFL{\\}} and integrated two new blockchain-based decentralized federated learning mechanisms to try to try to make the decentralized federated learning algorithm better landed.", "ENTRYTYPE": "article", "ID": "Hu2020"}, {"year": "2020", "url": "http://arxiv.org/abs/2009.05868", "title": "{From Federated Learning to Federated Neural Architecture Search: A Survey}", "file": ":Users/rm/CETIC/RESEARCH{\\_}THEMES/Federated Learning/2009.05868.pdf:pdf", "eprint": "2009.05868", "author": "Zhu, Hangyu and Zhang, Haoyu and Jin, Yaochu", "arxivid": "2009.05868", "archiveprefix": "arXiv", "abstract": "Federated learning is a recently proposed distributed machine learning paradigm for privacy preservation, which has found a wide range of applications where data privacy is of primary concern. Meanwhile, neural architecture search has become very popular in deep learning for automatically tuning the architecture and hyperparameters of deep neural networks. While both federated learning and neural architecture search are faced with many open challenges, searching for optimized neural architectures in the federated learning framework is particularly demanding. This survey paper starts with a brief introduction to federated learning, including both horizontal, vertical, and hybrid federated learning. Then, neural architecture search approaches based on reinforcement learning, evolutionary algorithms and gradient-based are presented. This is followed by a description of federated neural architecture search that has recently been proposed, which is categorized into online and offline implementations, and single- and multi-objective search approaches. Finally, remaining open research questions are outlined and promising research topics are suggested.", "ENTRYTYPE": "article", "ID": "Zhu2020b"}, {"year": "2020", "title": "{From distributed machine learning to federated learning: In the view of data privacy and security}", "keywords": "data privacy,distributed machine learning,federated learning,security", "journal": "Concurrency Computation ", "issn": "15320634", "file": ":Users/rm/CETIC/RESEARCH{\\_}THEMES/Federated Learning/2010.09258.pdf:pdf", "eprint": "arXiv:2010.09258v1", "doi": "10.1002/cpe.6002", "author": "Shen, Sheng and Zhu, Tianqing and Wu, Di and Wang, Wei and Zhou, Wanlei", "arxivid": "arXiv:2010.09258v1", "archiveprefix": "arXiv", "abstract": "Federated learning is an improved version of distributed machine learning that further offloads operations which would usually be performed by a central server. The server becomes more like an assistant coordinating clients to work together rather than micromanaging the workforce as in traditional DML. One of the greatest advantages of federated learning is the additional privacy and security guarantees it affords. Federated learning architecture relies on smart devices, such as smartphones and IoT sensors, that collect and process their own data, so sensitive information never has to leave the client device. Rather, clients train a submodel locally and send an encrypted update to the central server for aggregation into the global model. These strong privacy guarantees make federated learning an attractive choice in a world where data breaches and information theft are common and serious threats. This survey outlines the landscape and latest developments in data privacy and security for federated learning. We identify the different mechanisms used to provide privacy and security, such as differential privacy, secure multiparty computation and secure aggregation. We also survey the current attack models, identifying the areas of vulnerability and the strategies adversaries use to penetrate federated systems. The survey concludes with a discussion on the open challenges and potential directions of future work in this increasingly popular learning paradigm.", "ENTRYTYPE": "article", "ID": "Shen2020"}, {"year": "2020", "url": "http://arxiv.org/abs/2010.09767{\\%}0Ahttps://arxiv.org/abs/2010.09767?s=09", "title": "{FLAP -- A Federated Learning Framework for Attribute-based Access Control Policies}", "mendeley-tags": "framework", "keywords": "framework", "file": ":Users/rm/CETIC/RESEARCH{\\_}THEMES/Federated Learning/2010.09767.pdf:pdf", "eprint": "2010.09767", "author": "Jabal, Amani Abu and Bertino, Elisa and Lobo, Jorge and Verma, Dinesh and Calo, Seraphin and Russo, Alessandra", "arxivid": "2010.09767", "archiveprefix": "arXiv", "abstract": "Technology advances in areas such as sensors, IoT, and robotics, enable new collaborative applications (e.g., autonomous devices). A primary requirement for such collaborations is to have a secure system which enables information sharing and information flow protection. Policy-based management system is a key mechanism for secure selective sharing of protected resources. However, policies in each party of such a collaborative environment cannot be static as they have to adapt to different contexts and situations. One advantage of collaborative applications is that each party in the collaboration can take advantage of knowledge of the other parties for learning or enhancing its own policies. We refer to this learning mechanism as policy transfer. The design of a policy transfer framework has challenges, including policy conflicts and privacy issues. Policy conflicts typically arise because of differences in the obligations of the parties, whereas privacy issues result because of data sharing constraints for sensitive data. Hence, the policy transfer framework should be able to tackle such challenges by considering minimal sharing of data and support policy adaptation to address conflict. In the paper we propose a framework that aims at addressing such challenges. We introduce a formal definition of the policy transfer problem for attribute-based policies. We then introduce the transfer methodology that consists of three sequential steps. Finally we report experimental results.", "ENTRYTYPE": "article", "ID": "Jabal2020"}, {"year": "2020", "title": "{FedSmart: An Auto Updating Federated Learning Optimization Mechanism}", "pages": "716--724", "keywords": "distributed,federated learning,federated optimization,machine learning,privacy preserving", "issn": "16113349", "isbn": "9783030602581", "file": ":Users/rm/CETIC/RESEARCH{\\_}THEMES/Federated Learning/2009.07455.pdf:pdf", "eprint": "2009.07455", "doi": "10.1007/978-3-030-60259-8_52", "author": "He, Anxun and Wang, Jianzong and Huang, Zhangcheng and Xiao, Jing", "arxivid": "2009.07455", "archiveprefix": "arXiv", "abstract": "Federated learning has made an important contribution to data privacy-preserving. Many previous works are based on the assumption that the data are independently identically distributed (IID). As a result, the model performance on non-identically independently distributed (non-IID) data is beyond expectation, which is the concrete situation. Some existing methods of ensuring the model robustness on non-IID data, like the data-sharing strategy or pretraining, may lead to privacy leaking. In addition, there exist some participants who try to poison the model with low-quality data. In this paper, a performance-based parameter return method for optimization is introduced, we term it FederatedSmart (FedSmart). It optimizes different model for each client through sharing global gradients, and it extracts the data from each client as a local validation set, and the accuracy that model achieves in round t determines the weights of the next round. The experiment results show that FedSmart enables the participants to allocate a greater weight to the ones with similar data distribution.", "ENTRYTYPE": "article", "ID": "He2020"}, {"year": "2020", "url": "http://arxiv.org/abs/2010.08982", "title": "{Federated Unsupervised Representation Learning}", "mendeley-tags": "concepts", "keywords": "concepts", "file": ":Users/rm/CETIC/RESEARCH{\\_}THEMES/Federated Learning/2010.08982.pdf:pdf", "eprint": "2010.08982", "author": "Zhang, Fengda and Kuang, Kun and You, Zhaoyang and Shen, Tao and Xiao, Jun and Zhang, Yin and Wu, Chao and Zhuang, Yueting and Li, Xiaolin", "arxivid": "2010.08982", "archiveprefix": "arXiv", "abstract": "To leverage enormous unlabeled data on distributed edge devices, we formulate a new problem in federated learning called Federated Unsupervised Representation Learning (FURL) to learn a common representation model without supervision while preserving data privacy. FURL poses two new challenges: (1) data distribution shift (Non-IID distribution) among clients would make local models focus on different categories, leading to the inconsistency of representation spaces. (2) without the unified information among clients in FURL, the representations across clients would be misaligned. To address these challenges, we propose Federated Constrastive Averaging with dictionary and alignment (FedCA) algorithm. FedCA is composed of two key modules: (1) dictionary module to aggregate the representations of samples from each client and share with all clients for consistency of representation space and (2) alignment module to align the representation of each client on a base model trained on a public data. We adopt the contrastive loss for local model training. Through extensive experiments with three evaluation protocols in IID and Non-IID settings, we demonstrate that FedCA outperforms all baselines with significant margins.", "ENTRYTYPE": "article", "ID": "Zhang2020"}, {"year": "2020", "url": "http://arxiv.org/abs/2010.15561", "title": "{Federated Transfer Learning: concept and applications}", "pages": "1--17", "mendeley-tags": "concepts", "keywords": "concepts", "file": ":Users/rm/CETIC/RESEARCH{\\_}THEMES/Federated Learning/2010.15561.pdf:pdf", "eprint": "2010.15561", "author": "Saha, Sudipan and Ahmad, Tahir", "arxivid": "2010.15561", "archiveprefix": "arXiv", "abstract": "Development of Artificial Intelligence (AI) is inherently tied to the development of data. However, in most industries data exists in form of isolated islands, with limited scope of sharing between different organizations. This is an hindrance to the further development of AI. Federated learning has emerged as a possible solution to this problem in the last few years without compromising user privacy. Among different variants of the federated learning, noteworthy is federated transfer learning (FTL) that allows knowledge to be transferred across domains that do not have many overlapping features and users. In this work we provide a comprehensive survey of the existing works on this topic. In more details, we study the background of FTL and its different existing applications. We further analyze FTL from privacy and machine learning perspective.", "ENTRYTYPE": "article", "ID": "Saha2020"}, {"year": "2016", "url": "http://arxiv.org/abs/1610.02527", "title": "{Federated Optimization: Distributed Machine Learning for On-Device Intelligence}", "pages": "1--38", "mendeley-tags": "concepts", "keywords": "concepts", "file": ":Users/rm/CETIC/RESEARCH{\\_}THEMES/Federated Learning/1610.02527.pdf:pdf", "eprint": "1610.02527", "author": "Kone{\u010d}n{\u00fd}, Jakub and McMahan, H. Brendan and Ramage, Daniel and Richt{\u00e1}rik, Peter", "arxivid": "1610.02527", "archiveprefix": "arXiv", "abstract": "We introduce a new and increasingly relevant setting for distributed optimization in machine learning, where the data defining the optimization are unevenly distributed over an extremely large number of nodes. The goal is to train a high-quality centralized model. We refer to this setting as Federated Optimization. In this setting, communication efficiency is of the utmost importance and minimizing the number of rounds of communication is the principal goal. A motivating example arises when we keep the training data locally on users' mobile devices instead of logging it to a data center for training. In federated optimziation, the devices are used as compute nodes performing computation on their local data in order to update a global model. We suppose that we have extremely large number of devices in the network --- as many as the number of users of a given service, each of which has only a tiny fraction of the total data available. In particular, we expect the number of data points available locally to be much smaller than the number of devices. Additionally, since different users generate data with different patterns, it is reasonable to assume that no device has a representative sample of the overall distribution. We show that existing algorithms are not suitable for this setting, and propose a new algorithm which shows encouraging experimental results for sparse convex problems. This work also sets a path for future research needed in the context of $\\backslash$federated optimization.", "ENTRYTYPE": "article", "ID": "Konecny2016"}, {"year": "2018", "url": "http://arxiv.org/abs/1812.06127", "title": "{Federated Optimization in Heterogeneous Networks}", "mendeley-tags": "concepts", "keywords": "concepts", "file": ":Users/rm/CETIC/RESEARCH{\\_}THEMES/Federated Learning/1812.06127.pdf:pdf", "eprint": "1812.06127", "author": "Li, Tian and Sahu, Anit Kumar and Zaheer, Manzil and Sanjabi, Maziar and Talwalkar, Ameet and Smith, Virginia", "arxivid": "1812.06127", "archiveprefix": "arXiv", "abstract": "Federated Learning is a distributed learning paradigm with two key challenges that differentiate it from traditional distributed optimization: (1) significant variability in terms of the systems characteristics on each device in the network (systems heterogeneity), and (2) non-identically distributed data across the network (statistical heterogeneity). In this work, we introduce a framework, FedProx, to tackle heterogeneity in federated networks. FedProx can be viewed as a generalization and re-parametrization of FedAvg, the current state-of-the-art method for federated learning. While this re-parameterization makes only minor modifications to the method itself, these modifications have important ramifications both in theory and in practice. Theoretically, we provide convergence guarantees for our framework when learning over data from non-identical distributions (statistical heterogeneity), and while adhering to device-level systems constraints by allowing each participating device to perform a variable amount of work (systems heterogeneity). Practically, we demonstrate that FedProx allows for more robust convergence than FedAvg across a suite of realistic federated datasets. In particular, in highly heterogeneous settings, FedProx demonstrates significantly more stable and accurate convergence behavior relative to FedAvg---improving absolute test accuracy by 22{\\%} on average.", "ENTRYTYPE": "article", "ID": "Li2018"}, {"year": "2019", "volume": "10", "title": "{Federated machine learning: Concept and applications}", "pages": "1--19", "number": "2", "mendeley-tags": "applications,concepts", "keywords": "Federated learning,GDPR,applications,concepts,transfer learning", "journal": "ACM Transactions on Intelligent Systems and Technology", "issn": "21576912", "file": ":Users/rm/CETIC/RESEARCH{\\_}THEMES/Federated Learning/1902.04885.pdf:pdf", "eprint": "1902.04885", "doi": "10.1145/3298981", "author": "Yang, Qiang and Liu, Yang and Chen, Tianjian and Tong, Yongxin", "arxivid": "1902.04885", "archiveprefix": "arXiv", "abstract": "Today's artificial intelligence still faces two major challenges. One is that, in most industries, data exists in the form of isolated islands. The other is the strengthening of data privacy and security.We propose a possible solution to these challenges: Secure federated learning. Beyond the federated-learning framework first proposed by Google in 2016, we introduce a comprehensive secure federated-learning framework, which includes horizontal federated learning, vertical federated learning, and federated transfer learning.We provide definitions, architectures, and applications for the federated-learning framework, and provide a comprehensive survey of existing works on this subject. In addition, we propose building data networks among organizations based on federated mechanisms as an effective solution to allowing knowledge to be shared without compromising user privacy.", "ENTRYTYPE": "article", "ID": "Yang2019"}, {"year": "2020", "url": "http://arxiv.org/abs/2011.01815", "title": "{Federated LQR: Learning through Sharing}", "pages": "1--65", "file": ":Users/rm/CETIC/RESEARCH{\\_}THEMES/Federated Learning/2011.01815.pdf:pdf", "eprint": "2011.01815", "author": "Ren, Zhaolin and Zhong, Aoxiao and Zhou, Zhengyuan and Li, Na", "arxivid": "2011.01815", "archiveprefix": "arXiv", "abstract": "In many multi-agent reinforcement learning applications such as flocking, multi-robot applications and smart manufacturing, distinct agents share similar dynamics but face different objectives. In these applications, an important question is how the similarities amongst the agents can accelerate learning in spite of the agents' differing goals. We study a distributed LQR (Linear Quadratic Regulator) tracking problem which models this setting, where the agents, acting independently, share identical (unknown) dynamics and cost structure but need to track different targets. In this paper, we propose a communication-efficient, federated model-free zeroth-order algorithm that provably achieves a convergence speedup linear in the number of agents compared with the communication-free setup where each agent's problem is treated independently. We support our arguments with numerical simulations of both linear and nonlinear systems.", "ENTRYTYPE": "article", "ID": "Ren2020"}, {"year": "2020", "volume": "37", "title": "{Federated Learning: Challenges, Methods, and Future Directions}", "pages": "50--60", "number": "3", "mendeley-tags": "concepts", "keywords": "concepts", "journal": "IEEE Signal Processing Magazine", "issn": "15580792", "file": ":Users/rm/CETIC/RESEARCH{\\_}THEMES/Federated Learning/1908.07873.pdf:pdf", "eprint": "1908.07873", "doi": "10.1109/MSP.2020.2975749", "author": "Li, Tian and Sahu, Anit Kumar and Talwalkar, Ameet and Smith, Virginia", "arxivid": "1908.07873", "archiveprefix": "arXiv", "abstract": "Federated learning involves training statistical models over remote devices or siloed data centers, such as mobile phones or hospitals, while keeping data localized. Training in heterogeneous and potentially massive networks introduces novel challenges that require a fundamental departure from standard approaches for large-scale machine learning, distributed optimization, and privacy-preserving data analysis. In this article, we discuss the unique characteristics and challenges of federated learning, provide a broad overview of current approaches, and outline several directions of future work that are relevant to a wide range of research communities.", "ENTRYTYPE": "article", "ID": "Li2020"}, {"year": "2018", "url": "http://arxiv.org/abs/1806.00582", "title": "{Federated Learning with Non-IID Data}", "mendeley-tags": "concepts", "keywords": "concepts", "file": ":Users/rm/CETIC/RESEARCH{\\_}THEMES/Federated Learning/1806.00582.pdf:pdf", "eprint": "1806.00582", "author": "Zhao, Yue and Li, Meng and Lai, Liangzhen and Suda, Naveen and Civin, Damon and Chandra, Vikas", "arxivid": "1806.00582", "archiveprefix": "arXiv", "abstract": "Federated learning enables resource-constrained edge compute devices, such as mobile phones and IoT devices, to learn a shared model for prediction, while keeping the training data local. This decentralized approach to train models provides privacy, security, regulatory and economic benefits. In this work, we focus on the statistical challenge of federated learning when local data is non-IID. We first show that the accuracy of federated learning reduces significantly, by up to 55{\\%} for neural networks trained for highly skewed non-IID data, where each client device trains only on a single class of data. We further show that this accuracy reduction can be explained by the weight divergence, which can be quantified by the earth mover's distance (EMD) between the distribution over classes on each device and the population distribution. As a solution, we propose a strategy to improve training on non-IID data by creating a small subset of data which is globally shared between all the edge devices. Experiments show that accuracy can be increased by 30{\\%} for the CIFAR-10 dataset with only 5{\\%} globally shared data.", "ENTRYTYPE": "article", "ID": "Zhao2018"}, {"year": "2020", "url": "http://arxiv.org/abs/2010.05273", "title": "{Federated Learning via Posterior Averaging: A New Perspective and Practical Algorithms}", "mendeley-tags": "concepts", "keywords": "concepts", "file": ":Users/rm/CETIC/RESEARCH{\\_}THEMES/Federated Learning/2010.05273.pdf:pdf", "eprint": "2010.05273", "author": "Al-Shedivat, Maruan and Gillenwater, Jennifer and Xing, Eric and Rostamizadeh, Afshin", "arxivid": "2010.05273", "archiveprefix": "arXiv", "abstract": "Federated learning is typically approached as an optimization problem, where the goal is to minimize a global loss function by distributing computation across client devices that possess local data and specify different parts of the global objective. We present an alternative perspective and formulate federated learning as a posterior inference problem, where the goal is to infer a global posterior distribution by having client devices each infer the posterior of their local data. While exact inference is often intractable, this perspective provides a principled way to search for global optima in federated settings. Further, starting with the analysis of federated quadratic objectives, we develop a computation- and communication-efficient approximate posterior inference algorithm -- federated posterior averaging (FedPA). Our algorithm uses MCMC for approximate inference of local posteriors on the clients and efficiently communicates their statistics to the server, where the latter uses them to refine a global estimate of the posterior mode. Finally, we show that FedPA generalizes federated averaging (FedAvg), can similarly benefit from adaptive optimizers, and yields state-of-the-art results on four realistic and challenging benchmarks, converging faster, to better optima.", "ENTRYTYPE": "article", "ID": "Al-Shedivat2020"}, {"year": "2020", "url": "http://arxiv.org/abs/2010.02056", "title": "{Federated learning using a mixture of experts}", "pages": "1--8", "file": ":Users/rm/CETIC/RESEARCH{\\_}THEMES/Federated Learning/2010.02056.pdf:pdf", "eprint": "2010.02056", "author": "Zec, Edvin Listo and Mogren, Olof and Martinsson, John and S{\u00fc}tfeld, Leon Ren{\u00e9} and Gillblad, Daniel", "arxivid": "2010.02056", "archiveprefix": "arXiv", "abstract": "Federated learning has received attention for its efficiency and privacy benefits, in settings where data is distributed among devices. Although federated learning shows significant promise as a key approach when data cannot be shared or centralized, current incarnations show limited privacy properties and have shortcomings when applied to common real-world scenarios. One such scenario is heterogeneous data among devices, where data may come from different generating distributions. In this paper, we propose a federated learning framework using a mixture of experts to balance the specialist nature of a locally trained model with the generalist knowledge of a global model in a federated learning setting. Our results show that the mixture of experts model is better suited as a personalized model for devices when data is heterogeneous, outperforming both global and local models. Furthermore, our framework gives strict privacy guarantees, which allows clients to select parts of their data that may be excluded from the federation. The evaluation shows that the proposed solution is robust to the setting where some users require a strict privacy setting and do not disclose their models to a central server at all, opting out from the federation partially or entirely. The proposed framework is general enough to include any kind of machine learning models, and can even use combinations of different kinds.", "ENTRYTYPE": "article", "ID": "Zec2020"}, {"year": "2018", "title": "{Federated learning of predictive models from federated Electronic Health Records}", "pmid": "29500022", "mendeley-tags": "usecases", "keywords": "Distributed learning,Electronic Health Records (EHRs),Federated databases,Heart diseases,Hospitalization,Predictive models,usecases", "journal": "International Journal of Medical Informatics", "issn": "18728243", "doi": "10.1016/j.ijmedinf.2018.01.007", "author": "Brisimi, Theodora S. and Chen, Ruidi and Mela, Theofanie and Olshevsky, Alex and Paschalidis, Ioannis Ch and Shi, Wei", "abstract": "Background: In an era of \u201cbig data,\u201d computationally efficient and privacy-aware solutions for large-scale machine learning problems become crucial, especially in the healthcare domain, where large amounts of data are stored in different locations and owned by different entities. Past research has been focused on centralized algorithms, which assume the existence of a central data repository (database) which stores and can process the data from all participants. Such an architecture, however, can be impractical when data are not centrally located, it does not scale well to very large datasets, and introduces single-point of failure risks which could compromise the integrity and privacy of the data. Given scores of data widely spread across hospitals/individuals, a decentralized computationally scalable methodology is very much in need. Objective: We aim at solving a binary supervised classification problem to predict hospitalizations for cardiac events using a distributed algorithm. We seek to develop a general decentralized optimization framework enabling multiple data holders to collaborate and converge to a common predictive model, without explicitly exchanging raw data. Methods: We focus on the soft-margin l1-regularized sparse Support Vector Machine (sSVM) classifier. We develop an iterative cluster Primal Dual Splitting (cPDS) algorithm for solving the large-scale sSVM problem in a decentralized fashion. Such a distributed learning scheme is relevant for multi-institutional collaborations or peer-to-peer applications, allowing the data holders to collaborate, while keeping every participant's data private. Results: We test cPDS on the problem of predicting hospitalizations due to heart diseases within a calendar year based on information in the patients Electronic Health Records prior to that year. cPDS converges faster than centralized methods at the cost of some communication between agents. It also converges faster and with less communication overhead compared to an alternative distributed algorithm. In both cases, it achieves similar prediction accuracy measured by the Area Under the Receiver Operating Characteristic Curve (AUC) of the classifier. We extract important features discovered by the algorithm that are predictive of future hospitalizations, thus providing a way to interpret the classification results and inform prevention efforts.", "ENTRYTYPE": "article", "ID": "Brisimi2018"}, {"year": "2020", "url": "http://arxiv.org/abs/2010.13333", "title": "{Federated Learning in Multi-RIS Aided Systems}", "pages": "1--30", "file": ":Users/rm/CETIC/RESEARCH{\\_}THEMES/Federated Learning/2010.13333.pdf:pdf", "eprint": "2010.13333", "author": "Ni, Wanli and Liu, Yuanwei and Yang, Zhaohui and Tian, Hui and Shen, Xuemin", "arxivid": "2010.13333", "archiveprefix": "arXiv", "abstract": "This paper investigates the problem of model aggregation in the federated learning system aided by multiple reconfigurable intelligent surfaces. The effective combination of computation and communication is achieved by over-the-air computation in federated learning. Since all local parameters are transmitted over shared wireless channels, the undesirable propagation error will inevitably deteriorate the learning performance. The objective of this work is to reduce the signal distortion and improve the convergence rate of federated learning. Thus, the mean-square-error and weighted cardinality are minimized by optimizing the transmit power, controlling the receive scalar, designing the phase shifts, and selecting devices in the model uploading process. To address this challenging issue, the original mixed-integer bi-criterion problem (P0) is decomposed into a non-convex problem (P1) with continuous variables and a combinatorial problem (P2) with integer variables. In an effort to tackle P1, the closed-form expressions for transceivers are first derived, and the multi-antenna cases are addressed by the semidefinite relaxation, then the problem of phase shifts design is tackled by invoking the penalty method and successive convex approximation. In terms of P2, the difference-of-convex programming is adopted to select devices judiciously for convergence accelerating, while satisfying the aggregation error demand. After that, an alternating optimization algorithm is proposed to find a suboptimal solution for P0, where the corresponding convergence and complexity are analyzed. Finally, simulation results demonstrate that the designed algorithm can converge faster and aggregate model more accurately.", "ENTRYTYPE": "article", "ID": "Ni2020"}, {"year": "2020", "url": "http://arxiv.org/abs/2010.07808", "title": "{Federated Learning in Adversarial Settings}", "mendeley-tags": "security", "keywords": "bandwidth efficient,differential privacy,federated,learning,privacy-preserving,robustness,security", "file": ":Users/rm/CETIC/RESEARCH{\\_}THEMES/Federated Learning/2010.07808.pdf:pdf", "eprint": "2010.07808", "author": "Kerkouche, Raouf and {\u00c1}cs, Gergely and Castelluccia, Claude", "arxivid": "2010.07808", "archiveprefix": "arXiv", "abstract": "Federated Learning enables entities to collaboratively learn a shared prediction model while keeping their training data locally. It prevents data collection and aggregation and, therefore, mitigates the associated privacy risks. However, it still remains vulnerable to various security attacks where malicious participants aim at degrading the generated model, inserting backdoors, or inferring other participants' training data. This paper presents a new federated learning scheme that provides different trade-offs between robustness, privacy, bandwidth efficiency, and model accuracy. Our scheme uses biased quantization of model updates and hence is bandwidth efficient. It is also robust against state-of-the-art backdoor as well as model degradation attacks even when a large proportion of the participant nodes are malicious. We propose a practical differentially private extension of this scheme which protects the whole dataset of participating entities. We show that this extension performs as efficiently as the non-private but robust scheme, even with stringent privacy requirements but are less robust against model degradation and backdoor attacks. This suggests a possible fundamental trade-off between Differential Privacy and robustness.", "ENTRYTYPE": "article", "ID": "Kerkouche2020"}, {"year": "2020", "url": "http://arxiv.org/abs/2009.13012", "title": "{Federated Learning for Internet of Things: Recent Advances, Taxonomy, and Open Challenges}", "pages": "1--30", "file": ":Users/rm/CETIC/RESEARCH{\\_}THEMES/Federated Learning/2009.13012.pdf:pdf", "eprint": "2009.13012", "author": "Khan, Latif U. and Saad, Walid and Han, Zhu and Hossain, Ekram and Hong, Choong Seon", "arxivid": "2009.13012", "archiveprefix": "arXiv", "abstract": "The Internet of Things (IoT) will be ripe for the deployment of novel machine learning algorithms for both network and application management. However, given the presence of massively distributed and private datasets, it is challenging to use classical centralized learning algorithms in the IoT. To overcome this challenge, federated learning can be a promising solution that enables on-device machine learning without the need to migrate the private end-user data to a central cloud. In federated learning, only learning model updates are transferred between end-devices and the aggregation server. Although federated learning can offer better privacy preservation than centralized machine learning, it has still privacy concerns. In this paper, first, we present the recent advances of federated learning towards enabling federated learning-powered IoT applications. A set of metrics such as sparsification, robustness, quantization, scalability, security, and privacy, is delineated in order to rigorously evaluate the recent advances. Second, we devise a taxonomy for federated learning over IoT networks. Third, we propose two IoT use cases of dispersed federated learning that can offer better privacy preservation than federated learning. Finally, we present several open research challenges with their possible solutions.", "ENTRYTYPE": "article", "ID": "Khan2020"}, {"year": "2020", "url": "http://arxiv.org/abs/2009.10190", "title": "{Federated Learning for Computational Pathology on Gigapixel Whole Slide Images}", "keywords": "computational pathology,digital pathology,distributed learning,federated learning,pathology,split learning,whole slide imaging", "file": ":Users/rm/CETIC/RESEARCH{\\_}THEMES/Federated Learning/2009.10190.pdf:pdf", "eprint": "2009.10190", "author": "Lu, Ming Y. and Kong, Dehan and Lipkova, Jana and Chen, Richard J. and Singh, Rajendra and Williamson, Drew F. K. and Chen, Tiffany Y. and Mahmood, Faisal", "arxivid": "2009.10190", "archiveprefix": "arXiv", "abstract": "Deep Learning-based computational pathology algorithms have demonstrated profound ability to excel in a wide array of tasks that range from characterization of well known morphological phenotypes to predicting non-human-identifiable features from histology such as molecular alterations. However, the development of robust, adaptable, and accurate deep learning-based models often rely on the collection and time-costly curation large high-quality annotated training data that should ideally come from diverse sources and patient populations to cater for the heterogeneity that exists in such datasets. Multi-centric and collaborative integration of medical data across multiple institutions can naturally help overcome this challenge and boost the model performance but is limited by privacy concerns amongst other difficulties that may arise in the complex data sharing process as models scale towards using hundreds of thousands of gigapixel whole slide images. In this paper, we introduce privacy-preserving federated learning for gigapixel whole slide images in computational pathology using weakly-supervised attention multiple instance learning and differential privacy. We evaluated our approach on two different diagnostic problems using thousands of histology whole slide images with only slide-level labels. Additionally, we present a weakly-supervised learning framework for survival prediction and patient stratification from whole slide images and demonstrate its effectiveness in a federated setting. Our results show that using federated learning, we can effectively develop accurate weakly supervised deep learning models from distributed data silos without direct data sharing and its associated complexities, while also preserving differential privacy using randomized noise generation.", "ENTRYTYPE": "article", "ID": "Lu2020"}, {"year": "2020", "volume": "12444 LNCS", "title": "{Federated Learning for Breast Density Classification: A Real-World Implementation}", "pages": "181--191", "number": "Dl", "mendeley-tags": "usecases", "keywords": "BI-RADS,Breast density classification,Federated learning,Mammography,usecases", "journal": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)", "issn": "16113349", "isbn": "9783030605476", "file": ":Users/rm/CETIC/RESEARCH{\\_}THEMES/Federated Learning/2009.01871.pdf:pdf", "eprint": "2009.01871", "doi": "10.1007/978-3-030-60548-3_18", "author": "Roth, Holger R. and Chang, Ken and Singh, Praveer and Neumark, Nir and Li, Wenqi and Gupta, Vikash and Gupta, Sharut and Qu, Liangqiong and Ihsani, Alvin and Bizzo, Bernardo C. and Wen, Yuhong and Buch, Varun and Shah, Meesam and Kitamura, Felipe and Mendon{\u00e7}a, Matheus and Lavor, Vitor and Harouni, Ahmed and Compas, Colin and Tetreault, Jesse and Dogra, Prerna and Cheng, Yan and Erdal, Selnur and White, Richard and Hashemian, Behrooz and Schultz, Thomas and Zhang, Miao and McCarthy, Adam and Yun, B. Min and Sharaf, Elshaimaa and Hoebel, Katharina V. and Patel, Jay B. and Chen, Bryan and Ko, Sean and Leibovitz, Evan and Pisano, Etta D. and Coombs, Laura and Xu, Daguang and Dreyer, Keith J. and Dayan, Ittai and Naidu, Ram C. and Flores, Mona and Rubin, Daniel and Kalpathy-Cramer, Jayashree", "arxivid": "2009.01871", "archiveprefix": "arXiv", "abstract": "Building robust deep learning-based models requires large quantities of diverse training data. In this study, we investigate the use of federated learning (FL) to build medical imaging classification models in a real-world collaborative setting. Seven clinical institutions from across the world joined this FL effort to train a model for breast density classification based on Breast Imaging, Reporting {\\&} Data System (BI-RADS). We show that despite substantial differences among the datasets from all sites (mammography system, class distribution, and data set size) and without centralizing data, we can successfully train AI models in federation. The results show that models trained using FL perform 6.3{\\%} on average better than their counterparts trained on an institute's local data alone. Furthermore, we show a 45.8{\\%} relative improvement in the models' generalizability when evaluated on the other participating sites' testing data.", "ENTRYTYPE": "article", "ID": "Roth2020"}, {"year": "2020", "volume": "13", "title": "{Federated Learning}", "pages": "1--207", "number": "3", "mendeley-tags": "concepts", "keywords": "GDPR,artificial intelligence,concepts,data confidentiality,federated learning,machine learning algorithms,privacy preserving machine learning,privacy regulations,secure multi-party computation,transfer learning", "issn": "19394616", "doi": "10.2200/S00960ED2V01Y201910AIM043", "booktitle": "Synthesis Lectures on Artificial Intelligence and Machine Learning", "author": "Yang, Qiang and Liu, Yang and Cheng, Yong and Kang, Yan and Chen, Tianjian and Yu, Han", "abstract": "How is it possible to allow multiple data owners to collaboratively train and use a shared prediction model while keeping all the local training data private Traditional machine learning approaches need to combine all data at one location, typically a data center, which may very well violate the laws on user privacy and data confidentiality. Today, many parts of the world demand that technology companies treat user data carefully according to user-privacy laws. The European Union's General Data Protection Regulation (GDPR) is a prime example. In this book, we describe how federated machine learning addresses this problem with novel solutions combining distributed machine learning, cryptography and security, and incentive mechanism design based on economic principles and game theory. We explain different types of privacy-preserving machine learning solutions and their technological backgrounds, and highlight some representative practical use cases. We show how federated learning can become the foundation of next-generation machine learning that caters to technological and societal needs for responsible AI development and application. Table of Contents: Preface / Acknowledgments / Introduction / Background / Distributed Machine Learning / Horizontal Federated Learning / Vertical Federated Learning / Federated Transfer Learning / Incentive Mechanism Design for Federated Learning / Federated Learning for Vision, Language, and Recommendation / Federated Reinforcement Learning / Selected Applications / Summary and Outlook / Bibliography / Authors' Biographies", "ENTRYTYPE": "incollection", "ID": "Yang2020"}, {"year": "2020", "url": "http://arxiv.org/abs/2011.02367", "title": "{Federated Knowledge Distillation}", "pages": "1--30", "file": ":Users/rm/CETIC/RESEARCH{\\_}THEMES/Federated Learning/2011.02367.pdf:pdf", "eprint": "2011.02367", "author": "Seo, Hyowoon and Park, Jihong and Oh, Seungeun and Bennis, Mehdi and Kim, Seong-Lyun", "arxivid": "2011.02367", "archiveprefix": "arXiv", "abstract": "Distributed learning frameworks often rely on exchanging model parameters across workers, instead of revealing their raw data. A prime example is federated learning that exchanges the gradients or weights of each neural network model. Under limited communication resources, however, such a method becomes extremely costly particularly for modern deep neural networks having a huge number of model parameters. In this regard, federated distillation (FD) is a compelling distributed learning solution that only exchanges the model outputs whose dimensions are commonly much smaller than the model sizes (e.g., 10 labels in the MNIST dataset). The goal of this chapter is to provide a deep understanding of FD while demonstrating its communication efficiency and applicability to a variety of tasks. To this end, towards demystifying the operational principle of FD, the first part of this chapter provides a novel asymptotic analysis for two foundational algorithms of FD, namely knowledge distillation (KD) and co-distillation (CD), by exploiting the theory of neural tangent kernel (NTK). Next, the second part elaborates on a baseline implementation of FD for a classification task, and illustrates its performance in terms of accuracy and communication efficiency compared to FL. Lastly, to demonstrate the applicability of FD to various distributed learning tasks and environments, the third part presents two selected applications, namely FD over asymmetric uplink-and-downlink wireless channels and FD for reinforcement learning.", "ENTRYTYPE": "article", "ID": "Seo2020"}, {"year": "2020", "url": "http://arxiv.org/abs/2010.10154", "title": "{Federated Bayesian Optimization via Thompson Sampling}", "number": "NeurIPS", "file": ":Users/rm/CETIC/RESEARCH{\\_}THEMES/Federated Learning/2010.10154.pdf:pdf", "eprint": "2010.10154", "author": "Dai, Zhongxiang and Low, Kian Hsiang and Jaillet, Patrick", "arxivid": "2010.10154", "archiveprefix": "arXiv", "abstract": "Bayesian optimization (BO) is a prominent approach to optimizing expensive-to-evaluate black-box functions. The massive computational capability of edge devices such as mobile phones, coupled with privacy concerns, has led to a surging interest in federated learning (FL) which focuses on collaborative training of deep neural networks (DNNs) via first-order optimization techniques. However, some common machine learning tasks such as hyperparameter tuning of DNNs lack access to gradients and thus require zeroth-order/black-box optimization. This hints at the possibility of extending BO to the FL setting (FBO) for agents to collaborate in these black-box optimization tasks. This paper presents federated Thompson sampling (FTS) which overcomes a number of key challenges of FBO and FL in a principled way: We (a) use random Fourier features to approximate the Gaussian process surrogate model used in BO, which naturally produces the parameters to be exchanged between agents, (b) design FTS based on Thompson sampling, which significantly reduces the number of parameters to be exchanged, and (c) provide a theoretical convergence guarantee that is robust against heterogeneous agents, which is a major challenge in FL and FBO. We empirically demonstrate the effectiveness of FTS in terms of communication efficiency, computational efficiency, and practical performance.", "ENTRYTYPE": "article", "ID": "Dai2020"}, {"year": "2020", "url": "http://arxiv.org/abs/2009.10748", "title": "{FedCluster: Boosting the Convergence of Federated Learning via Cluster-Cycling}", "file": ":Users/rm/CETIC/RESEARCH{\\_}THEMES/Federated Learning/2009.10748.pdf:pdf", "eprint": "2009.10748", "author": "Chen, Cheng and Chen, Ziyi and Zhou, Yi and Kailkhura, Bhavya", "arxivid": "2009.10748", "archiveprefix": "arXiv", "abstract": "We develop FedCluster--a novel federated learning framework with improved optimization efficiency, and investigate its theoretical convergence properties. The FedCluster groups the devices into multiple clusters that perform federated learning cyclically in each learning round. Therefore, each learning round of FedCluster consists of multiple cycles of meta-update that boost the overall convergence. In nonconvex optimization, we show that FedCluster with the devices implementing the local {\\{}stochastic gradient descent (SGD){\\}} algorithm achieves a faster convergence rate than the conventional {\\{}federated averaging (FedAvg){\\}} algorithm in the presence of device-level data heterogeneity. We conduct experiments on deep learning applications and demonstrate that FedCluster converges significantly faster than the conventional federated learning under diverse levels of device-level data heterogeneity for a variety of local optimizers.", "ENTRYTYPE": "article", "ID": "Chen2020"}, {"year": "2020", "url": "http://arxiv.org/abs/2009.06303", "title": "{Fed+: A Family of Fusion Algorithms for Federated Learning}", "pages": "1--21", "mendeley-tags": "framework", "keywords": "framework", "file": ":Users/rm/CETIC/RESEARCH{\\_}THEMES/Federated Learning/2009.06303.pdf:pdf", "eprint": "2009.06303", "author": "Yu, Pengqian and Wynter, Laura and Lim, Shiau Hong", "arxivid": "2009.06303", "archiveprefix": "arXiv", "abstract": "We present a class of methods for federated learning, which we call Fed+, pronounced FedPlus. The class of methods encompasses and unifies a number of recent algorithms proposed for federated learning and permits easily defining many new algorithms. The principal advantage of this class of methods is to better accommodate the real-world characteristics found in federated learning training, such as the lack of IID data across the parties in the federation. We demonstrate the use and benefits of this class of algorithms on standard benchmark datasets and a challenging real-world problem where catastrophic failure has a serious impact, namely in financial portfolio management.", "ENTRYTYPE": "article", "ID": "Yu2020"}, {"year": "2020", "url": "http://arxiv.org/abs/2010.10152", "title": "{Feature Inference Attack on Model Predictions in Vertical Federated Learning}", "pages": "1--12", "mendeley-tags": "security", "keywords": "security", "file": ":Users/rm/CETIC/RESEARCH{\\_}THEMES/Federated Learning/2010.10152.pdf:pdf", "eprint": "2010.10152", "author": "Luo, Xinjian and Wu, Yuncheng and Xiao, Xiaokui and Ooi, Beng Chin", "arxivid": "2010.10152", "archiveprefix": "arXiv", "abstract": "Federated learning (FL) is an emerging paradigm for facilitating multiple organizations' data collaboration without revealing their private data to each other. Recently, vertical FL, where the participating organizations hold the same set of samples but with disjoint features and only one organization owns the labels, has received increased attention. This paper presents several feature inference attack methods to investigate the potential privacy leakages in the model prediction stage of vertical FL. The attack methods consider the most stringent setting that the adversary controls only the trained vertical FL model and the model predictions, relying on no background information. We first propose two specific attacks on the logistic regression (LR) and decision tree (DT) models, according to individual prediction output. We further design a general attack method based on multiple prediction outputs accumulated by the adversary to handle complex models, such as neural networks (NN) and random forest (RF) models. Experimental evaluations demonstrate the effectiveness of the proposed attacks and highlight the need for designing private mechanisms to protect the prediction outputs in vertical FL.", "ENTRYTYPE": "article", "ID": "Luo2020"}, {"year": "2020", "url": "http://arxiv.org/abs/2009.11248", "title": "{FastSecAgg: Scalable Secure Aggregation for Privacy-Preserving Federated Learning}", "number": "November", "mendeley-tags": "privacy", "keywords": "data sketching,federated learning,learning,machine,privacy,privacy-preserving protocols,secret sharing,secure aggregation", "file": ":Users/rm/CETIC/RESEARCH{\\_}THEMES/Federated Learning/2009.11248.pdf:pdf", "eprint": "2009.11248", "author": "Kadhe, Swanand and Rajaraman, Nived and Koyluoglu, O. Ozan and Ramchandran, Kannan", "arxivid": "2009.11248", "archiveprefix": "arXiv", "abstract": "Recent attacks on federated learning demonstrate that keeping the training data on clients' devices does not provide sufficient privacy, as the model parameters shared by clients can leak information about their training data. A 'secure aggregation' protocol enables the server to aggregate clients' models in a privacy-preserving manner. However, existing secure aggregation protocols incur high computation/communication costs, especially when the number of model parameters is larger than the number of clients participating in an iteration -- a typical scenario in federated learning. In this paper, we propose a secure aggregation protocol, FastSecAgg, that is efficient in terms of computation and communication, and robust to client dropouts. The main building block of FastSecAgg is a novel multi-secret sharing scheme, FastShare, based on the Fast Fourier Transform (FFT), which may be of independent interest. FastShare is information-theoretically secure, and achieves a trade-off between the number of secrets, privacy threshold, and dropout tolerance. Riding on the capabilities of FastShare, we prove that FastSecAgg is (i) secure against the server colluding with 'any' subset of some constant fraction (e.g. {\\$}\\backslashsim10\\backslash{\\%}{\\$}) of the clients in the honest-but-curious setting; and (ii) tolerates dropouts of a 'random' subset of some constant fraction (e.g. {\\$}\\backslashsim10\\backslash{\\%}{\\$}) of the clients. FastSecAgg achieves significantly smaller computation cost than existing schemes while achieving the same (orderwise) communication cost. In addition, it guarantees security against adaptive adversaries, which can perform client corruptions dynamically during the execution of the protocol.", "ENTRYTYPE": "article", "ID": "Kadhe2020"}, {"year": "2020", "url": "http://arxiv.org/abs/2010.05057", "title": "{Fairness-aware Agnostic Federated Learning}", "mendeley-tags": "concepts", "keywords": "concepts", "file": ":Users/rm/CETIC/RESEARCH{\\_}THEMES/Federated Learning/2010.05057.pdf:pdf", "eprint": "2010.05057", "author": "Du, Wei and Xu, Depeng and Wu, Xintao and Tong, Hanghang", "arxivid": "2010.05057", "archiveprefix": "arXiv", "abstract": "Federated learning is an emerging framework that builds centralized machine learning models with training data distributed across multiple devices. Most of the previous works about federated learning focus on the privacy protection and communication cost reduction. However, how to achieve fairness in federated learning is under-explored and challenging especially when testing data distribution is different from training distribution or even unknown. Introducing simple fairness constraints on the centralized model cannot achieve model fairness on unknown testing data. In this paper, we develop a fairness-aware agnostic federated learning framework (AgnosticFair) to deal with the challenge of unknown testing distribution. We use kernel reweighing functions to assign a reweighing value on each training sample in both loss function and fairness constraint. Therefore, the centralized model built from AgnosticFair can achieve high accuracy and fairness guarantee on unknown testing data. Moreover, the built model can be directly applied to local sites as it guarantees fairness on local data distributions. To our best knowledge, this is the first work to achieve fairness in federated learning. Experimental results on two real datasets demonstrate the effectiveness in terms of both utility and fairness under data shift scenarios.", "ENTRYTYPE": "article", "ID": "Du2020"}, {"year": "2020", "url": "http://arxiv.org/abs/2010.01175", "title": "{F2ED-Learning: Good Fences Make Good Neighbors}", "pages": "1--10", "mendeley-tags": "concepts", "keywords": "concepts", "file": ":Users/rm/CETIC/RESEARCH{\\_}THEMES/Federated Learning/2010.01175.pdf:pdf", "eprint": "2010.01175", "author": "Wang, Lun and Pang, Qi and Wang, Shuai and Song, Dawn", "arxivid": "2010.01175", "archiveprefix": "arXiv", "abstract": "In this paper, we present F2ED-Learning, the first federated learning protocol simultaneously defending against both a semi-honest server and Byzantine malicious clients. Using a robust mean estimator called FilterL2, F2ED-Learning is the first FL protocol providing dimension-free estimation error against Byzantine malicious clients. Besides, F2ED-Learning leverages secure aggregation to protect the clients from a semi-honest server who wants to infer the clients' information from the legitimate updates. The main challenge stems from the incompatibility between FilterL2 and secure aggregation. Specifically, to run FilterL2, the server needs to access individual updates from clients while secure aggregation hides those updates from it. We propose to split the clients into shards, securely aggregate each shard's updates and run FilterL2 on the updates from different shards. The evaluation shows that F2ED-Learning consistently achieves optimal or sub-optimal performance under three attacks among five robust FL protocols.", "ENTRYTYPE": "article", "ID": "Wang2020a"}, {"year": "2020", "url": "http://arxiv.org/abs/2009.09371", "title": "{Estimation of Individual Device Contributions for Incentivizing Federated Learning}", "mendeley-tags": "concepts", "keywords": "concepts", "file": ":Users/rm/CETIC/RESEARCH{\\_}THEMES/Federated Learning/2009.09371.pdf:pdf", "eprint": "2009.09371", "author": "Nishio, Takayuki and Shinkuma, Ryoichi and Mandayam, Narayan B.", "arxivid": "2009.09371", "archiveprefix": "arXiv", "abstract": "Federated learning (FL) is an emerging technique used to train a machine-learning model collaboratively using the data and computation resource of the mobile devices without exposing privacy-sensitive user data. Appropriate incentive mechanisms that motivate the data and mobile-device owner to participate in FL is key to building a sustainable platform for FL. However, it is difficult to evaluate the contribution level of the devices/owners to determine appropriate rewards without large computation and communication overhead. This paper proposes a computation-and communication-efficient method of estimating a participating device's contribution level. The proposed method enables such estimation during a single FL training process, there by reducing the need for traffic and computation overhead. The performance evaluations using the MNIST dataset show that the proposed method estimates individual participants' contributions accurately with 46-49{\\%} less computation overhead and no communication overhead than a naive estimation method.", "ENTRYTYPE": "article", "ID": "Nishio2020"}, {"year": "2020", "volume": "14", "url": "http://arxiv.org/abs/2009.10401", "title": "{Dynamic Fusion based Federated Learning for COVID-19 Detection}", "pages": "1--9", "number": "8", "file": ":Users/rm/CETIC/RESEARCH{\\_}THEMES/Federated Learning/2009.10401.pdf:pdf", "eprint": "2009.10401", "author": "Zhang, Weishan and Zhou, Tao and Lu, Qinghua and Wang, Xiao and Zhu, Chunsheng and Sun, Haoyun and Wang, Zhipeng and Lo, Sin Kit and Wang, Fei-Yue", "arxivid": "2009.10401", "archiveprefix": "arXiv", "abstract": "Medical diagnostic image analysis (e.g., CT scan or X-Ray) using machine learning is an efficient and accurate way to detect COVID-19 infections. However, sharing diagnostic images across medical institutions is usually not allowed due to the concern of patients' privacy. This causes the issue of insufficient datasets for training the image classification model. Federated learning is an emerging privacy-preserving machine learning paradigm that produces an unbiased global model based on the received updates of local models trained by clients without exchanging clients' local data. Nevertheless, the default setting of federated learning introduces huge communication cost of transferring model updates and can hardly ensure model performance when data heterogeneity of clients heavily exists. To improve communication efficiency and model performance, in this paper, we propose a novel dynamic fusion-based federated learning approach for medical diagnostic image analysis to detect COVID-19 infections. First, we design an architecture for dynamic fusion-based federated learning systems to analyse medical diagnostic images. Further, we present a dynamic fusion method to dynamically decide the participating clients according to their local model performance and schedule the model fusion-based on participating clients' training time. In addition, we summarise a category of medical diagnostic image datasets for COVID-19 detection, which can be used by the machine learning community for image analysis. The evaluation results show that the proposed approach is feasible and performs better than the default setting of federated learning in terms of model performance, communication efficiency and fault tolerance.", "ENTRYTYPE": "article", "ID": "Zhang2020a"}, {"year": "2020", "url": "http://arxiv.org/abs/2010.05867", "title": "{Differentially Private Secure Multi-Party Computation for Federated Learning in Financial Applications}", "keywords": "2020,acm reference format,david byrd and antigoni,differentially private secure,federated learning,finance,multiagent,polychroniadou,privacy,simulation", "isbn": "9781450375849", "file": ":Users/rm/CETIC/RESEARCH{\\_}THEMES/Federated Learning/2010.05867.pdf:pdf", "eprint": "2010.05867", "author": "Byrd, David and Polychroniadou, Antigoni", "arxivid": "2010.05867", "archiveprefix": "arXiv", "abstract": "Federated Learning enables a population of clients, working with a trusted server, to collaboratively learn a shared machine learning model while keeping each client's data within its own local systems. This reduces the risk of exposing sensitive data, but it is still possible to reverse engineer information about a client's private data set from communicated model parameters. Most federated learning systems therefore use differential privacy to introduce noise to the parameters. This adds uncertainty to any attempt to reveal private client data, but also reduces the accuracy of the shared model, limiting the useful scale of privacy-preserving noise. A system can further reduce the coordinating server's ability to recover private client information, without additional accuracy loss, by also including secure multiparty computation. An approach combining both techniques is especially relevant to financial firms as it allows new possibilities for collaborative learning without exposing sensitive client data. This could produce more accurate models for important tasks like optimal trade execution, credit origination, or fraud detection. The key contributions of this paper are: We present a privacy-preserving federated learning protocol to a non-specialist audience, demonstrate it using logistic regression on a real-world credit card fraud data set, and evaluate it using an open-source simulation platform which we have adapted for the development of federated learning systems.", "ENTRYTYPE": "article", "ID": "Byrd2020"}, {"year": "2020", "url": "http://arxiv.org/abs/2010.06177", "title": "{COVID-19 Imaging Data Privacy by Federated Learning Design: A Theoretical Framework}", "keywords": "covid-19,differential privacy,federated learning systems,pbd,privacy by design", "file": ":Users/rm/CETIC/RESEARCH{\\_}THEMES/Federated Learning/2010.06177.pdf:pdf", "eprint": "2010.06177", "author": "Ulhaq, Anwaar and Burmeister, Oliver", "arxivid": "2010.06177", "archiveprefix": "arXiv", "abstract": "To address COVID-19 healthcare challenges, we need frequent sharing of health data, knowledge and resources at a global scale. However, in this digital age, data privacy is a big concern that requires the secure embedding of privacy assurance into the design of all technological solutions that use health data. In this paper, we introduce differential privacy by design (dPbD) framework and discuss its embedding into the federated machine learning system. To limit the scope of our paper, we focus on the problem scenario of COVID-19 imaging data privacy for disease diagnosis by computer vision and deep learning approaches. We discuss the evaluation of the proposed design of federated machine learning systems and discuss how differential privacy by design (dPbD) framework can enhance data privacy in federated learning systems with scalability and robustness. We argue that scalable differentially private federated learning design is a promising solution for building a secure, private and collaborative machine learning model such as required to combat COVID19 challenge.", "ENTRYTYPE": "article", "ID": "Ulhaq2020"}, {"year": "2017", "volume": "54", "title": "{Communication-efficient learning of deep networks from decentralized data}", "mendeley-tags": "fundamentals", "keywords": "fundamentals", "journal": "Proceedings of the 20th International Conference on Artificial Intelligence and Statistics, AISTATS 2017", "file": ":Users/rm/CETIC/RESEARCH{\\_}THEMES/Federated Learning/1602.05629.pdf:pdf", "eprint": "1602.05629", "author": "{Brendan McMahan}, H. and Moore, Eider and Ramage, Daniel and Hampson, Seth and {Ag{\u00fc}era y Arcas}, Blaise", "arxivid": "1602.05629", "archiveprefix": "arXiv", "abstract": "Modern mobile devices have access to a wealth of data suitable for learning models, which in turn can greatly improve the user experience on the device. For example, language models can improve speech recognition and text entry, and image models can automatically select good photos. However, this rich data is often privacy sensitive, large in quantity, or both, which may preclude logging to the data center and training there using conventional approaches. We advocate an alternative that leaves the training data distributed on the mobile devices, and learns a shared model by aggregating locally-computed updates. We term this decentralized approach Federated Learning. We present a practical method for the federated learning of deep networks based on iterative model averaging, and conduct an extensive empirical evaluation, considering five different model architectures and four datasets. These experiments demonstrate the approach is robust to the unbalanced and non-IID data distributions that are a defining characteristic of this setting. Communication costs are the principal constraint, and we show a reduction in required communication rounds by 10\u2013100x as compared to synchronized stochastic gradient descent.", "ENTRYTYPE": "article", "ID": "BrendanMcMahan2017"}, {"year": "2020", "volume": "14", "url": "http://arxiv.org/abs/2011.02883", "title": "{Collaborative City Digital Twin For Covid-19 Pandemic: A Federated Learning Solution}", "pages": "1--8", "number": "8", "mendeley-tags": "usecases", "keywords": "usecases", "file": ":Users/rm/CETIC/RESEARCH{\\_}THEMES/Federated Learning/2011.02883.pdf:pdf", "eprint": "2011.02883", "author": "Pang, Junjie and Li, Jianbo and Xie, Zhenzhen and Huang, Yan and Cai, Zhipeng", "arxivid": "2011.02883", "archiveprefix": "arXiv", "abstract": "In this work, we propose a collaborative city digital twin based on FL, a novel paradigm that allowing multiple city DT to share the local strategy and status in a timely manner. In particular, an FL central server manages the local updates of multiple collaborators (city DT), provides a global model which is trained in multiple iterations at different city DT systems, until the model gains the correlations between various response plan and infection trend. That means, a collaborative city DT paradigm based on FL techniques can obtain knowledge and patterns from multiple DTs, and eventually establish a `global view' for city crisis management. Meanwhile, it also helps to improve each city digital twin selves by consolidating other DT's respective data without violating privacy rules. To validate the proposed solution, we take COVID-19 pandemic as a case study. The experimental results on the real dataset with various response plan validate our proposed solution and demonstrate the superior performance.", "ENTRYTYPE": "article", "ID": "Pang2020"}, {"year": "2020", "volume": "1", "url": "http://arxiv.org/abs/2010.07427", "title": "{BlockFLA: Accountable Federated Learning via Hybrid Blockchain Architecture}", "publisher": "Association for Computing Machinery", "number": "1", "keywords": "Hybrid Blockchain, Hyperledger, Ethereum, Machine Learning, Backdoor attacks, Federated Learning, Federated Averaging,all or part of,backdoor attacks,ethereum,federated averaging,federated learning,hybrid blockchain,hyperledger,machine learning,or,or hard copies of,permission to make digital,this work for personal", "file": ":Users/rm/CETIC/RESEARCH{\\_}THEMES/Federated Learning/2010.07427.pdf:pdf", "eprint": "2010.07427", "booktitle": "Proceedings of ACM Conference (Conference'17)", "author": "Desai, Harsh Bimal and Ozdayi, Mustafa Safa and Kantarcioglu, Murat", "arxivid": "2010.07427", "archiveprefix": "arXiv", "abstract": "Federated Learning (FL) is a distributed, and decentralized machine learning protocol. By executing FL, a set of agents can jointly train a model without sharing their datasets with each other, or a third-party. This makes FL particularly suitable for settings where data privacy is desired. At the same time, concealing training data gives attackers an opportunity to inject backdoors into the trained model. It has been shown that an attacker can inject backdoors to the trained model during FL, and then can leverage the backdoor to make the model misclassify later. Several works tried to alleviate this threat by designing robust aggregation functions. However, given more sophisticated attacks are developed over time, which by-pass the existing defenses, we approach this problem from a complementary angle in this work. Particularly, we aim to discourage backdoor attacks by detecting, and punishing the attackers, possibly after the end of training phase. To this end, we develop a hybrid blockchain-based FL framework that uses smart contracts to automatically detect, and punish the attackers via monetary penalties. Our framework is general in the sense that, any aggregation function, and any attacker detection algorithm can be plugged into it. We conduct experiments to demonstrate that our framework preserves the communication-efficient nature of FL, and provide empirical results to illustrate that it can successfully penalize attackers by leveraging our novel attacker detection algorithm.", "ENTRYTYPE": "book", "ID": "Desai2020"}, {"year": "2019", "title": "{Bayesian nonparametric federated learning of neural networks}", "mendeley-tags": "fundamentals", "keywords": "fundamentals", "isbn": "9781510886988", "eprint": "1905.12022", "booktitle": "36th International Conference on Machine Learning, ICML 2019", "author": "Yurochkin, Mikhail and Agarwal, Mayank and Ghosh, Soumya and Greenewald, Kristjan and Hoang, Trong Nghia and Khazaeni, Yasaman", "arxivid": "1905.12022", "archiveprefix": "arXiv", "abstract": "In federated learning problems, data is scattered across different servers and exchanging or pooling it is often impractical or prohibited. We develop a Bayesian nonparametric framework for federated learning with neural networks. Each data server is assumed to provide local neural network weights, which are modeled through our framework. We then develop an inference approach that allows us to synthesize a more expressive global network without additional supervision, data pooling and with as few as a single communication round. We then demonstrate the efficacy of our approach on federated learning problems simulated from two popular image classification datasets.", "ENTRYTYPE": "inproceedings", "ID": "Yurochkin2019"}, {"title": "{BaFFLe: Backdoor detection via Feedback-based Federated Learning}", "file": ":Users/rm/CETIC/RESEARCH{\\_}THEMES/Federated Learning/2011.02167.pdf:pdf", "eprint": "arXiv:2011.02167v1", "author": "\u52ff\u4f20", "arxivid": "arXiv:2011.02167v1", "archiveprefix": "arXiv", "ENTRYTYPE": "article", "ID": "Unknown"}, {"year": "2020", "volume": "12444 LNCS", "title": "{Automated Pancreas Segmentation Using Multi-institutional Collaborative Deep Learning}", "pages": "192--200", "keywords": "Federated learning,Neural architecture search,Pancreas segmentation", "journal": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)", "issn": "16113349", "isbn": "9783030605476", "file": ":Users/rm/CETIC/RESEARCH{\\_}THEMES/Federated Learning/2009.13148.pdf:pdf", "eprint": "2009.13148", "doi": "10.1007/978-3-030-60548-3_19", "author": "Wang, Pochuan and Shen, Chen and Roth, Holger R. and Yang, Dong and Xu, Daguang and Oda, Masahiro and Misawa, Kazunari and Chen, Po Ting and Liu, Kao Lang and Liao, Wei Chih and Wang, Weichung and Mori, Kensaku", "arxivid": "2009.13148", "archiveprefix": "arXiv", "abstract": "The performance of deep learning based methods strongly relies on the number of datasets used for training. Many efforts have been made to increase the data in the medical image analysis field. However, unlike photography images, it is hard to generate centralized databases to collect medical images because of numerous technical, legal, and privacy issues. In this work, we study the use of federated learning between two institutions in a real-world setting to collaboratively train a model without sharing the raw data across national boundaries. We quantitatively compare the segmentation models obtained with federated learning and local training alone. Our experimental results show that federated learning models have higher generalizability than standalone training.", "ENTRYTYPE": "article", "ID": "Wang2020b"}, {"year": "2019", "title": "{Analyzing federated learning through an adversarial lens}", "mendeley-tags": "security", "keywords": "security", "isbn": "9781510886988", "eprint": "1811.12470", "booktitle": "36th International Conference on Machine Learning, ICML 2019", "author": "Bhagoji, Arjun Nitin and Chakraborty, Supriyo and Mittal, Prateek and Calo, Seraphin", "arxivid": "1811.12470", "archiveprefix": "arXiv", "abstract": "Federated learning distributes model training among a multitude of agents, who, guided by privacy concerns, perform training using their local data but share only model parameter updates, for iterative aggregation at the server to train an overall global model. In this work, we explore how the federated learning setting gives rise to a new threat, namely model poisoning, different from traditional data poisoning. Model poisoning is carried out by an adversary controlling a small number of malicious agents (usually 1) with the aim of causing the global model to mis-classify a set of chosen inputs with high confidence. We explore a number of attack strategies for deep neural networks, starting with targeted model poisoning using boosting of the malicious agent's update to overcome the effects of other agents. We also propose two critical notions of stealth to detect malicious updates. We bypass these by including them in the adversarial objective to carry out stealthy model poisoning. We improve attack stealth with the use of an alternating minimization strategy which alternately optimizes for stealth and the adversarial objective. We also empirically demonstrate that Byzantine-resilient aggregation strategies are not robust to our attacks. Our results show that effective and stealthy model poisoning attacks arc possible, highlighting vulnerabilities in the federated learning setting.", "ENTRYTYPE": "inproceedings", "ID": "Bhagoji2019"}, {"year": "2019", "title": "{Agnostic federated learning}", "mendeley-tags": "concepts", "keywords": "concepts", "isbn": "9781510886988", "eprint": "1902.00146", "booktitle": "36th International Conference on Machine Learning, ICML 2019", "author": "Mohri, Mehryar and Sivek, Gary and Suresh, Ananda Theertha", "arxivid": "1902.00146", "archiveprefix": "arXiv", "abstract": "A key learning scenario in large-scale applications is that of federated learning, where a centralized model is trained based on data originating from a large number of clients. We argue that, with the existing training and inference, federated models can be biased towards different clients. Instead, we propose a new framework of agnostic federated learning, where the centralized model is optimized for any target distribution formed by a mixture of the client distributions. We further show that this framework naturally yields a notion of fairness. We present data-dependent Rademacher complexity guarantees for learning with this objective, which guide the definition of an algorithm for agnostic federated learning. We also give a fast stochastic optimization algorithm for solving the corresponding optimization problem, for which we prove convergence bounds, assuming a convex loss function and a convex hypothesis set. We further empirically demonstrate the benefits of our approach in several datasets. Beyond federated learning, our framework and algorithm can be of interest to other learning scenarios such as cloud computing, domain adaptation, drifting, and other contexts where the training and test distributions do not coincide.", "ENTRYTYPE": "inproceedings", "ID": "Mohri2019"}, {"year": "2019", "url": "http://arxiv.org/abs/1912.04977", "title": "{Advances and Open Problems in Federated Learning}", "pages": "1--105", "mendeley-tags": "concepts", "keywords": "concepts", "file": ":Users/rm/CETIC/RESEARCH{\\_}THEMES/Federated Learning/advances and open problems.pdf:pdf", "eprint": "1912.04977", "author": "Kairouz, Peter and McMahan, H. Brendan and Avent, Brendan and Bellet, Aur{\u00e9}lien and Bennis, Mehdi and Bhagoji, Arjun Nitin and Bonawitz, Keith and Charles, Zachary and Cormode, Graham and Cummings, Rachel and D'Oliveira, Rafael G. L. and Rouayheb, Salim El and Evans, David and Gardner, Josh and Garrett, Zachary and Gasc{\u00f3}n, Adri{\u00e0} and Ghazi, Badih and Gibbons, Phillip B. and Gruteser, Marco and Harchaoui, Zaid and He, Chaoyang and He, Lie and Huo, Zhouyuan and Hutchinson, Ben and Hsu, Justin and Jaggi, Martin and Javidi, Tara and Joshi, Gauri and Khodak, Mikhail and Kone{\u010d}n{\u00fd}, Jakub and Korolova, Aleksandra and Koushanfar, Farinaz and Koyejo, Sanmi and Lepoint, Tancr{\u00e8}de and Liu, Yang and Mittal, Prateek and Mohri, Mehryar and Nock, Richard and {\u00d6}zg{\u00fc}r, Ayfer and Pagh, Rasmus and Raykova, Mariana and Qi, Hang and Ramage, Daniel and Raskar, Ramesh and Song, Dawn and Song, Weikang and Stich, Sebastian U. and Sun, Ziteng and Suresh, Ananda Theertha and Tram{\u00e8}r, Florian and Vepakomma, Praneeth and Wang, Jianyu and Xiong, Li and Xu, Zheng and Yang, Qiang and Yu, Felix X. and Yu, Han and Zhao, Sen", "arxivid": "1912.04977", "archiveprefix": "arXiv", "abstract": "Federated learning (FL) is a machine learning setting where many clients (e.g. mobile devices or whole organizations) collaboratively train a model under the orchestration of a central server (e.g. service provider), while keeping the training data decentralized. FL embodies the principles of focused data collection and minimization, and can mitigate many of the systemic privacy risks and costs resulting from traditional, centralized machine learning and data science approaches. Motivated by the explosive growth in FL research, this paper discusses recent advances and presents an extensive collection of open problems and challenges.", "ENTRYTYPE": "article", "ID": "Kairouz2019"}, {"year": "2020", "url": "http://arxiv.org/abs/2010.13058", "title": "{Adaptive Federated Learning and Digital Twin for Industrial Internet of Things}", "pages": "1--10", "file": ":Users/rm/CETIC/RESEARCH{\\_}THEMES/Federated Learning/2010.13058.pdf:pdf", "eprint": "2010.13058", "author": "Sun, Wen and Lei, Shiyu and Wang, Lu and Liu, Zhiqiang and Zhang, Yan", "arxivid": "2010.13058", "archiveprefix": "arXiv", "abstract": "Industrial Internet of Things (IoT) enables distributed intelligent services varying with the dynamic and realtime industrial devices to achieve Industry 4.0 benefits. In this paper, we consider a new architecture of digital twin empowered Industrial IoT where digital twins capture the characteristics of industrial devices to assist federated learning. Noticing that digital twins may bring estimation deviations from the actual value of device state, a trusted based aggregation is proposed in federated learning to alleviate the effects of such deviation. We adaptively adjust the aggregation frequency of federated learning based on Lyapunov dynamic deficit queue and deep reinforcement learning, to improve the learning performance under the resource constraints. To further adapt to the heterogeneity of Industrial IoT, a clustering-based asynchronous federated learning framework is proposed. Numerical results show that the proposed framework is superior to the benchmark in terms of learning accuracy, convergence, and energy saving.", "ENTRYTYPE": "article", "ID": "Sun2020"}, {"year": "2020", "volume": "35", "url": "http://arxiv.org/abs/1812.03337 http://dx.doi.org/10.1109/MIS.2020.2988525 https://ieeexplore.ieee.org/document/9076003/", "title": "{A Secure Federated Transfer Learning Framework}", "pages": "70--82", "number": "4", "month": "jul", "mendeley-tags": "framework", "keywords": "framework", "journal": "IEEE Intelligent Systems", "issn": "1541-1672", "eprint": "1812.03337", "doi": "10.1109/MIS.2020.2988525", "author": "Liu, Yang and Kang, Yan and Xing, Chaoping and Chen, Tianjian and Yang, Qiang", "arxivid": "1812.03337", "archiveprefix": "arXiv", "abstract": "Machine learning relies on the availability of a vast amount of data for training. However, in reality, most data are scattered across different organizations and cannot be easily integrated under many legal and practical constraints. In this paper, we introduce a new technique and framework, known as federated transfer learning (FTL), to improve statistical models under a data federation. The federation allows knowledge to be shared without compromising user privacy, and enables complimentary knowledge to be transferred in the network. As a result, a target-domain party can build more flexible and powerful models by leveraging rich labels from a source-domain party. A secure transfer cross validation approach is also proposed to guard the FTL performance under the federation. The framework requires minimal modifications to the existing model structure and provides the same level of accuracy as the non-privacy-preserving approach. This framework is very flexible and can be effectively adapted to various secure multi-party machine learning tasks.", "ENTRYTYPE": "article", "ID": "Liu2018"}, {"year": "2020", "url": "http://arxiv.org/abs/2010.06537", "title": "{A first look into the carbon footprint of federated learning}", "file": ":Users/rm/CETIC/RESEARCH{\\_}THEMES/Federated Learning/2010.06537.pdf:pdf", "eprint": "2010.06537", "author": "Qiu, Xinchi and Parcolle, Titouan and Beutel, Daniel J. and Topal, Taner and Mathur, Akhil and Lane, Nicholas D.", "arxivid": "2010.06537", "archiveprefix": "arXiv", "abstract": "Despite impressive results, deep learning-based technologies also raise severe privacy and environmental concerns induced by the training procedure often conducted in data centers. In response, alternatives to centralized training such as Federated Learning (FL) have emerged. Perhaps unexpectedly, FL in particular is starting to be deployed at a global scale by companies that must adhere to new legal demands and policies originating from governments and the civil society for privacy protection. However, the potential environmental impact related to FL remains unclear and unexplored. This paper offers the first-ever systematic study of the carbon footprint of FL. First, we propose a rigorous model to quantify the carbon footprint, hence facilitating the investigation of the relationship between FL design and carbon emissions. Then, we compare the carbon footprint of FL to traditional centralized learning. We also formalize an early-stage FL optimization problem enabling the community to consider the importance of optimizing the rate of CO{\\$}{\\_}2{\\$} emissions jointly to the accuracy of neural networks. Finally, we highlight and connect the reported results to the future challenges and trends in FL to reduce its environmental impact, including algorithms efficiency, hardware capabilities, and stronger industry transparency.", "ENTRYTYPE": "article", "ID": "Qiu2020"}, {"year": "2020", "url": "http://arxiv.org/abs/2010.10293", "title": "{A Federated Learning Approach to Anomaly Detection in Smart Buildings}", "pages": "1--9", "mendeley-tags": "usecases", "keywords": "federated learning,inter-,net of things,privacy by design,recurrent neural network,smart building,usecases", "file": ":Users/rm/CETIC/RESEARCH{\\_}THEMES/Federated Learning/2010.10293.pdf:pdf", "eprint": "2010.10293", "author": "Sater, Raed Abdel and Hamza, A. Ben", "arxivid": "2010.10293", "archiveprefix": "arXiv", "abstract": "Internet of Things (IoT) sensors in smart buildings are becoming increasingly ubiquitous, making buildings more livable, energy efficient, and sustainable. These devices sense the environment and generate multivariate temporal data of paramount importance for detecting anomalies and improving the prediction of energy usage in smart buildings. However, detecting these anomalies in centralized systems is often plagued by a huge delay in response time. To overcome this issue, we formulate the anomaly detection problem in a federated learning setting by leveraging the multi-task learning paradigm, which aims at solving multiple tasks simultaneously while taking advantage of the similarities and differences across tasks. We propose a novel privacy-by-design federated deep learning model based on a recurrent neural network architecture, and we demonstrate that it is more than twice as fast during training convergence compared to its centralized counterpart. The effectiveness of our federated learning approach is demonstrated on simulated datasets generated by following the distribution of real data from a General Electric Current smart building, achieving state-of-the-art performance compared to baseline methods in both classification and regression tasks.", "ENTRYTYPE": "article", "ID": "Sater2020"}, {"year": "2020", "volume": "1", "url": "http://arxiv.org/abs/2010.09687", "title": "{A Demonstration of Smart Doorbell Design Using Federated Deep Learning}", "publisher": "Association for Computing Machinery", "number": "1", "mendeley-tags": "usecases", "keywords": "Artificial Intelligence,Deep Learning,Federated Learning,Internet of Things,Machine Learning,Privacy,Security,Video Analytics,usecases", "file": ":Users/rm/CETIC/RESEARCH{\\_}THEMES/Federated Learning/2010.09687.pdf:pdf", "eprint": "2010.09687", "booktitle": "Proceedings of ACM Conference (Conference'17)", "author": "Patel, Vatsal and Kanani, Sarth and Pathak, Tapan and Patel, Pankesh and Ali, Muhammad Intizar and Breslin, John", "arxivid": "2010.09687", "archiveprefix": "arXiv", "abstract": "Smart doorbells have been playing an important role in protecting our modern homes. Existing approaches of sending video streams to a centralized server (or Cloud) for video analytics have been facing many challenges such as latency, bandwidth cost and more importantly users' privacy concerns. To address these challenges, this paper showcases the ability of an intelligent smart doorbell based on Federated Deep Learning, which can deploy and manage video analytics applications such as a smart doorbell across Edge and Cloud resources. This platform can scale, work with multiple devices, seamlessly manage online orchestration of the application components. The proposed framework is implemented using state-of-the-art technology. We implement the Federated Server using the Flask framework, containerized using Nginx and Gunicorn, which is deployed on AWS EC2 and AWS Serverless architecture.", "ENTRYTYPE": "book", "ID": "Patel2020"}]
